{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f5540a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.avro.functions import from_avro\n",
    "from pyspark.sql.functions import col, expr\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "SCHEMA_REGISTRY_URL = \"http://redpanda.kafka.svc:8081\"\n",
    "SUBJECT = \"blockchain.blocks.eth.mainnet-value\"\n",
    "BLOCKS_TOPIC = \"blockchain.blocks.eth.mainnet\"\n",
    "KAFKA_BROKER = \"redpanda.kafka.svc:9092\"\n",
    "checkpoint_path = \"s3a://datalake/_checkpoints/eth_mainnet_blocks\"\n",
    "\n",
    "avro_schema = requests.get(\n",
    "    f\"{SCHEMA_REGISTRY_URL}/subjects/{SUBJECT}/versions/latest\"\n",
    ").json()[\"schema\"]\n",
    "\n",
    "\n",
    "df = (\n",
    "    spark.readStream\n",
    "    .format(\"kafka\")\n",
    "    .option(\"kafka.bootstrap.servers\", KAFKA_BROKER)\n",
    "    .option(\"subscribe\", BLOCKS_TOPIC)\n",
    "    .option(\"startingOffsets\", \"earliest\")   # ⭐⭐⭐ Pull all data\n",
    "    .option(\"maxOffsetsPerTrigger\", 1000)   # ⭐⭐⭐ Avoid OOM\n",
    "    .load()\n",
    ")\n",
    "\n",
    "df_stripped = df.withColumn(\n",
    "    \"value_no_header\",\n",
    "    expr(\"substring(value, 6, length(value)-5)\") # skip magic + schema id\n",
    ")\n",
    "\n",
    "df_parsed = (\n",
    "    df_stripped.select(\n",
    "        from_avro(\n",
    "            col(\"value_no_header\"),\n",
    "            avro_schema,\n",
    "            {\"mode\": \"PERMISSIVE\"}\n",
    "        ).alias(\"r\")\n",
    "    )\n",
    "    .select(\"r.*\")\n",
    ")\n",
    "\n",
    "query = (\n",
    "    df_parsed\n",
    "    .writeStream\n",
    "    .format(\"iceberg\")\n",
    "    .outputMode(\"append\")\n",
    "    .option(\"checkpointLocation\", checkpoint_path)\n",
    "    .toTable(\"silver.eth_mainnet_blocks\")\n",
    ")\n",
    "\n",
    "query.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be32c4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create iceberg table\n",
    "spark.sql(\"\"\"\n",
    "    CREATE TABLE silver.eth_mainnet_blocks (\n",
    "        block_height BIGINT,\n",
    "        job_name STRING,\n",
    "        run_id STRING,\n",
    "        inserted_at STRING,\n",
    "        raw STRING\n",
    "    ) USING iceberg\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
