{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6ae63c-2d42-4867-a0ac-d1ec7447bab0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdataclasses\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dataclass\n\u001b[1;32m     16\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/jovyan/work\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01metherscan_blocks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_block_range_by_date\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkafka_blocks_state\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_last_state\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Environment Variables\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from confluent_kafka import Producer\n",
    "from confluent_kafka.schema_registry import SchemaRegistryClient\n",
    "from confluent_kafka.schema_registry.avro import AvroSerializer\n",
    "from confluent_kafka.serialization import SerializationContext, MessageField\n",
    "import json\n",
    "from datetime import datetime, timezone\n",
    "import uuid\n",
    "from typing import Optional\n",
    "from web3 import Web3\n",
    "from hexbytes import HexBytes\n",
    "from web3.datastructures import AttributeDict\n",
    "from dataclasses import dataclass\n",
    "\n",
    "sys.path.append(\"/home/jovyan/work\") \n",
    "from src.etherscan_blocks import get_block_range_by_date\n",
    "from src.kafka_blocks_state import load_last_state\n",
    "\n",
    "# -----------------------------\n",
    "# Environment Variables\n",
    "# -----------------------------\n",
    "\n",
    "JOB_DESC = os.getenv(\"JOB_NAME\", \"eth_backfill\")\n",
    "# INSTANCE_ID = os.getenv(\"INSTANCE_ID\", \"0\") # for parallel execution\n",
    "\n",
    "ETH_INFURA_RPC_URL = os.getenv(\"ETH_INFURA_RPC_URL\", \"https://mainnet.infura.io/v3/<YOUR_API_KEY>\")\n",
    "KAFKA_BROKER = os.getenv(\"KAFKA_BROKER\", \"redpanda.kafka.svc:9092\")\n",
    "SCHEMA_REGISTRY_URL = os.getenv(\"SCHEMA_REGISTRY_URL\", \"http://redpanda.kafka.svc:8081\")\n",
    "\n",
    "BLOCKS_TOPIC = os.getenv(\"BLOCKS_TOPIC\", \"blockchain.blocks.eth.mainnet\")\n",
    "STATE_TOPIC = os.getenv(\"STATE_TOPIC\", \"blockchain.ingestion-state.eth.mainnet\")\n",
    "STATE_KEY = os.getenv(\"STATE_KEY\", \"blockchain.ingestion-state.eth.mainnet-key\")\n",
    "\n",
    "BATCH_SIZE = int(os.getenv(\"BATCH_SIZE\", \"50\"))\n",
    "\n",
    "START_BLOCK = os.getenv(\"START_BLOCK\", \"24188501\")\n",
    "END_BLOCK = os.getenv(\"END_BLOCK\", \"24188600\")\n",
    "# START_BLOCK = os.getenv(\"START_BLOCK\")\n",
    "# END_BLOCK = os.getenv(\"END_BLOCK\")\n",
    "\n",
    "START_DATE = os.getenv(\"START_DATE\")\n",
    "END_DATE = os.getenv(\"END_DATE\")\n",
    "# START_DATE = os.getenv(\"START_DATE\", \"2026-01-01\")\n",
    "# END_DATE = os.getenv(\"END_DATE\", \"2026-01-01\")\n",
    "\n",
    "# =============================\n",
    "# Schema Registry\n",
    "# =============================\n",
    "schema_registry = SchemaRegistryClient({\n",
    "    \"url\": SCHEMA_REGISTRY_URL\n",
    "})\n",
    "\n",
    "current_utctime = datetime.now(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%S.%f\")[:-3] + \"Z\"\n",
    "\n",
    "run_id = str(uuid.uuid4())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "b627828b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# JSON safe serialization\n",
    "# -----------------------------\n",
    "def to_json_safe(obj):\n",
    "    if isinstance(obj, HexBytes):\n",
    "        return obj.hex()\n",
    "    elif isinstance(obj, AttributeDict):\n",
    "        return {k: to_json_safe(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, dict):\n",
    "        return {k: to_json_safe(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [to_json_safe(v) for v in obj]\n",
    "    else:\n",
    "        return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "38602319",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class BackfillContext:\n",
    "    start_block: int\n",
    "    end_block: int\n",
    "    job_name: str\n",
    "    mode: str  # block | date\n",
    "\n",
    "\n",
    "def resolve_backfill_context() -> BackfillContext: # type hint\n",
    "    \"\"\"\n",
    "    Priority:\n",
    "      BLOCK > DATE\n",
    "\n",
    "    Returns:\n",
    "      BackfillContext object\n",
    "    \"\"\"\n",
    "    if START_BLOCK and END_BLOCK:\n",
    "        start = int(START_BLOCK)\n",
    "        end = int(END_BLOCK)\n",
    "        \n",
    "        return BackfillContext(\n",
    "            start_block = start,\n",
    "            end_block = end,\n",
    "            job_name = f\"{JOB_DESC}_block_{start}_{end}\",\n",
    "            mode = \"block\",\n",
    "        )\n",
    "\n",
    "    if START_DATE and END_DATE:\n",
    "        start_block, end_block = get_block_range_by_date(\n",
    "            start_date = START_DATE,\n",
    "            end_date = END_DATE,\n",
    "        )\n",
    "        \n",
    "        date_key = f\"{START_DATE}_{END_DATE}\".replace(\"-\", \"\")\n",
    "        return BackfillContext(\n",
    "            start_block = start_block,\n",
    "            end_block = end_block,\n",
    "            job_name = f\"{JOB_DESC}_date_{date_key}\",\n",
    "            mode = \"date\",\n",
    "        )\n",
    "\n",
    "    raise RuntimeError(\n",
    "        \"Invalid backfill parameters : \"\n",
    "        \"Must provide either \"\"(START_BLOCK & END_BLOCK) \"\"or (START_DATE & END_DATE)\"\n",
    "    )\n",
    "    \n",
    "ctx = resolve_backfill_context()\n",
    "transactional_id = f\"blockchain.ingestion.eth.mainnet.{ctx.job_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "32076582",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_start_block() -> Optional[int]:\n",
    "    state = load_last_state(ctx.job_name)\n",
    "\n",
    "    # 1Ô∏è‚É£ Completed: exit the job\n",
    "    if state and state[\"status\"] == \"completed\":\n",
    "        print(f\"‚úÖ Backfill {ctx.job_name} already completed\")\n",
    "        sys.exit(0)   # üëà terminalate Python program\n",
    "\n",
    "    # 2Ô∏è‚É£ resume\n",
    "    if state:\n",
    "        last = state[\"last_processed_block\"]\n",
    "        end = state[\"end_block\"]\n",
    "\n",
    "        if last >= end:\n",
    "            print(f\"‚ö†Ô∏è State inconsistent: last >= end, treat as completed\")\n",
    "            sys.exit(0)\n",
    "\n",
    "        start_block = last + 1\n",
    "        print(f\"üîÅ Resume {ctx.job_name} from block {start_block}\")\n",
    "        return start_block\n",
    "\n",
    "    # 3Ô∏è‚É£ new job\n",
    "    print(f\"üöÄ Start new job {ctx.job_name} from block {ctx.start_block}\")\n",
    "    return ctx.start_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "df4a1728-5850-4bae-bd10-519a77e101fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# --- Avro schemasÔºàpull registryÔºâ\n",
    "blocks_value_schema = schema_registry.get_latest_version(\n",
    "    f\"{BLOCKS_TOPIC}-value\"\n",
    ").schema.schema_str\n",
    "\n",
    "state_value_schema = schema_registry.get_latest_version(\n",
    "    f\"{STATE_TOPIC}-value\"\n",
    ").schema.schema_str\n",
    "\n",
    "# =============================\n",
    "# Serializers\n",
    "# =============================\n",
    "blocks_value_serializer = AvroSerializer(\n",
    "    schema_registry,\n",
    "    blocks_value_schema\n",
    ")\n",
    "\n",
    "state_value_serializer = AvroSerializer(\n",
    "    schema_registry,\n",
    "    state_value_schema\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "a044d6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Web3\n",
    "# -----------------------------\n",
    "w3 = Web3(Web3.HTTPProvider(ETH_INFURA_RPC_URL))\n",
    "if not w3.is_connected():\n",
    "    raise RuntimeError(f\"Cannot connect to Ethereum RPC at {ETH_INFURA_RPC_URL}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Fetch block\n",
    "# -----------------------------\n",
    "def get_block(bn):\n",
    "    return w3.eth.get_block(bn, full_transactions=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "8f737d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Start new job eth_backfill_block_24188501_24188600 from block 24188501\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 164\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 165\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 166\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 167\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 168\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 169\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 170\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 171\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 172\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 173\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 174\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 175\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 176\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 177\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 178\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 179\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 180\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 181\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 182\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 183\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 184\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 185\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 186\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 187\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 188\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 189\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 190\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 191\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 192\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 193\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 194\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 195\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 196\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 197\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 198\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 199\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 200\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 201\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 202\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 203\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 204\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 205\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 206\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 207\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 208\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 209\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 210\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 211\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 212\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 213\n",
      "‚úÖ Delivered to blockchain.ingestion-state.eth.mainnet [0] @ 1\n",
      "‚úÖ backfilled 24188501 ‚Üí 24188550 \n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 216\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 217\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 218\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 219\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 220\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 221\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 222\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 223\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 224\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 225\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 226\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 227\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 228\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 229\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 230\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 231\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 232\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 233\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 234\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 235\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 236\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 237\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 238\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 239\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 240\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 241\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 242\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 243\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 244\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 245\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 246\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 247\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 248\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 249\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 250\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 251\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 252\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 253\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 254\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 255\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 256\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 257\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 258\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 259\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 260\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 261\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 262\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 263\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 264\n",
      "‚úÖ Delivered to blockchain.blocks.eth.mainnet [0] @ 265\n",
      "‚úÖ Delivered to blockchain.ingestion-state.eth.mainnet [0] @ 4\n",
      "‚úÖ backfilled 24188551 ‚Üí 24188600 \n",
      "üéâ Backfill finished\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Resolver for Dagster config, support passing parameters from Dagster\n",
    "# -----------------------------\n",
    "def delivery_report(err, msg):\n",
    "    if err is not None:\n",
    "        print(f\"‚ùå Delivery failed: {err}\")\n",
    "    else:\n",
    "        print(\n",
    "            f\"‚úÖ Delivered to {msg.topic()} \"\n",
    "            f\"[{msg.partition()}] @ {msg.offset()}\"\n",
    "        )\n",
    "\n",
    "# =============================\n",
    "# Producer\n",
    "# =============================\n",
    "producer = Producer({\n",
    "    \"bootstrap.servers\": KAFKA_BROKER,\n",
    "    \"enable.idempotence\": True,\n",
    "    \"acks\": \"all\",\n",
    "    \"retries\": 3,\n",
    "    \"linger.ms\": 5,\n",
    "    \"transactional.id\": transactional_id\n",
    "})\n",
    "\n",
    "producer.init_transactions()\n",
    "\n",
    "# -----------------------------\n",
    "# Backfill main logic\n",
    "# -----------------------------\n",
    "def backfill():\n",
    "\n",
    "    start = resolve_start_block()\n",
    "    end = ctx.end_block\n",
    "\n",
    "    # print(f\"{ctx.job_name}, backfill blocks [{start}, {end}]\", flush=True)\n",
    "\n",
    "    current = start\n",
    "    while current <= end:\n",
    "        batch_end = min(current + BATCH_SIZE - 1, end)\n",
    "\n",
    "        try:\n",
    "            producer.begin_transaction()\n",
    "\n",
    "            for bn in range(current, batch_end + 1):\n",
    "                block = get_block(bn)\n",
    "                block_dict = to_json_safe(dict(block))\n",
    "                block_dict.pop(\"transactions\", None)\n",
    "\n",
    "                block_record = {\n",
    "                    \"block_height\": bn,\n",
    "                    \"job_name\": ctx.job_name,\n",
    "                    \"run_id\": run_id,\n",
    "                    \"inserted_at\": current_utctime,\n",
    "                    \"raw\": json.dumps(block_dict),\n",
    "                }\n",
    "\n",
    "                producer.produce(\n",
    "                    topic=BLOCKS_TOPIC,\n",
    "                    key=str(bn),\n",
    "                    value=blocks_value_serializer(\n",
    "                        block_record,\n",
    "                        SerializationContext(BLOCKS_TOPIC, MessageField.VALUE)\n",
    "                    ),\n",
    "                    on_delivery=delivery_report,\n",
    "                )\n",
    "                \n",
    "            producer.poll(0)\n",
    "\n",
    "            # checking if all transaction is done\n",
    "            is_last_batch = batch_end >= end\n",
    "            status = \"completed\" if is_last_batch else \"running\"\n",
    "            \n",
    "            state_record = {\n",
    "                \"job_name\": ctx.job_name,\n",
    "                \"run_id\": run_id,\n",
    "                \"range\": {\n",
    "                    \"start\": start,\n",
    "                    \"end\": end\n",
    "                },\n",
    "                \"checkpoint\": batch_end,\n",
    "                \"status\": status,\n",
    "                \"inserted_at\": current_utctime\n",
    "            }\n",
    "\n",
    "            producer.produce(\n",
    "                STATE_TOPIC,\n",
    "                key=ctx.job_name,\n",
    "                value=state_value_serializer(\n",
    "                    state_record,\n",
    "                    SerializationContext(STATE_TOPIC, MessageField.VALUE)\n",
    "                ),\n",
    "                on_delivery=delivery_report,\n",
    "            )\n",
    "            \n",
    "            producer.poll(0)\n",
    "            producer.commit_transaction()\n",
    "\n",
    "            print(f\"‚úÖ backfilled {current} ‚Üí {batch_end} \", flush=True)\n",
    "            current = batch_end + 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"üî• abort batch {current}: {e}\", flush=True)\n",
    "\n",
    "            # abort transaction, rollback blocks\n",
    "            try:\n",
    "                producer.abort_transaction()\n",
    "            except Exception as abort_err:\n",
    "                print(f\"Abort transaction failed: {abort_err}\")\n",
    "\n",
    "            # normal write for failed status\n",
    "            failed_state = {\n",
    "                \"job_name\": ctx.job_name,\n",
    "                \"run_id\": run_id,\n",
    "                \"start_block\": start,\n",
    "                \"end_block\": end,\n",
    "                \"last_processed_block\": current - 1,  # the last success block\n",
    "                \"status\": \"failed\",\n",
    "                \"inserted_at\": current_utctime\n",
    "            }\n",
    "\n",
    "            producer.produce(\n",
    "                STATE_TOPIC,\n",
    "                key=ctx.job_name,\n",
    "                value=state_value_serializer(\n",
    "                    failed_state,\n",
    "                    SerializationContext(STATE_TOPIC, MessageField.VALUE)\n",
    "                ),\n",
    "                on_delivery=delivery_report,\n",
    "            )\n",
    "\n",
    "            producer.flush()\n",
    "\n",
    "            raise   # error capture for Dagster / k8s\n",
    "\n",
    "    print(\"üéâ Backfill finished\", flush=True)\n",
    "    producer.flush()\n",
    "\n",
    "# -----------------------------\n",
    "# Entrypoint\n",
    "# -----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    backfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b13c5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state topic:\n",
    "# Check point: 24137752\n",
    "\n",
    "# event topic:\n",
    "\n",
    "state_value = {\n",
    "    \"checkpoint\": 24138152,\n",
    "    \"inserted_at\": \"2026-01-09T06:00:05.417Z\",\n",
    "    \"job_name\": \"eth_backfill\",\n",
    "    \"range\": {\n",
    "        \"end\": 24143222,\n",
    "        \"start\": 24136053\n",
    "    },\n",
    "    \"run_id\": \"manual__2026-01-09T05:58:44.405997+00:00\",\n",
    "    \"status\": \"running\"\n",
    "}\n",
    "\n",
    "progress = (state_value.checkpoint - state_value.range.start) / (state_value.range.end - state_value.range.start)\n",
    "\n",
    "print(progress)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
