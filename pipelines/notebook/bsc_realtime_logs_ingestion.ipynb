{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab899cf1-781d-47d1-a1fc-d15ba60e15b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import uuid\n",
    "import time\n",
    "from datetime import datetime, timezone\n",
    "from web3 import Web3\n",
    "from web3.middleware import ExtraDataToPOAMiddleware\n",
    "from confluent_kafka import Producer\n",
    "from confluent_kafka.schema_registry import SchemaRegistryClient\n",
    "from confluent_kafka.schema_registry.avro import AvroSerializer\n",
    "from confluent_kafka.serialization import SerializationContext, MessageField\n",
    "from hexbytes import HexBytes\n",
    "from web3.datastructures import AttributeDict\n",
    "from src.kafka_state import load_last_state\n",
    "\n",
    "# -----------------------------\n",
    "# Environment Variables\n",
    "# -----------------------------\n",
    "INFURA_API_KEY = os.getenv(\"INFURA_API_KEY\", \"<YOUR-API-KEY>\")\n",
    "INFURA_BASE_URL = \"https://bsc-mainnet.infura.io/v3\"\n",
    "BSC_RPC_URL = f\"{INFURA_BASE_URL}/{INFURA_API_KEY}\"\n",
    "RUN_ID = os.getenv(\"RUN_ID\", str(uuid.uuid4()))\n",
    "\n",
    "POLL_BATCH_SIZE = int(os.getenv(\"BATCH_SIZE\", \"5\"))\n",
    "POLL_INTERVAL = int(os.getenv(\"POLL_INTERVAL\", \"5\"))\n",
    "BATCH_TX_SIZE = 10  # Max 10 transactions per batch\n",
    "\n",
    "# -----------------------------\n",
    "# Config\n",
    "# -----------------------------\n",
    "JOB_NAME = \"bsc_realtime\"\n",
    "TRANSACTIONAL_ID = f\"blockchain.ingestion.bsc.{JOB_NAME}\"\n",
    "KAFKA_BROKER = \"redpanda.kafka.svc:9092\"\n",
    "SCHEMA_REGISTRY_URL = \"http://redpanda.kafka.svc:8081\"\n",
    "BLOCKS_TOPIC = \"blockchain.logs.bsc\"\n",
    "STATE_TOPIC = \"blockchain.state.bsc\"\n",
    "PULL_BATCH_SIZE = int(os.getenv(\"BATCH_SIZE\", \"50\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752696c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def current_utctime():\n",
    "    \"\"\"Return the current UTC time string in ISO-8601 format with millisecond precision\"\"\"\n",
    "    return datetime.now(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%S.%f\")[:-3] + \"Z\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1637ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# JSON safe serialization\n",
    "# -----------------------------\n",
    "def to_json_safe(obj):\n",
    "    if isinstance(obj, HexBytes):\n",
    "        return obj.hex()\n",
    "    elif isinstance(obj, AttributeDict):\n",
    "        return {k: to_json_safe(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, dict):\n",
    "        return {k: to_json_safe(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [to_json_safe(v) for v in obj]\n",
    "    else:\n",
    "        return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "599af3b7-65ff-463a-8502-78ee73fdf0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Schema Registry\n",
    "# -----------------------------\n",
    "schema_registry = SchemaRegistryClient({\n",
    "    \"url\": SCHEMA_REGISTRY_URL\n",
    "})\n",
    "\n",
    "# --- Avro schemasÔºàpull registryÔºâ\n",
    "blocks_value_schema = schema_registry.get_latest_version(\n",
    "    f\"{BLOCKS_TOPIC}-value\"\n",
    ").schema.schema_str\n",
    "\n",
    "state_value_schema = schema_registry.get_latest_version(\n",
    "    f\"{STATE_TOPIC}-value\"\n",
    ").schema.schema_str\n",
    "\n",
    "# -----------------------------\n",
    "# Serializers\n",
    "# -----------------------------\n",
    "blocks_value_serializer = AvroSerializer(\n",
    "    schema_registry,\n",
    "    blocks_value_schema\n",
    ")\n",
    "\n",
    "state_value_serializer = AvroSerializer(\n",
    "    schema_registry,\n",
    "    state_value_schema\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94877bd8-f2b9-4c76-aa3a-7d8f63134dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Web3 initialization\n",
    "# -----------------------------\n",
    "w3 = Web3(Web3.HTTPProvider(BSC_RPC_URL))\n",
    "w3.middleware_onion.inject(ExtraDataToPOAMiddleware, layer=0)\n",
    "\n",
    "def fetch_block_logs(block_number):\n",
    "    return w3.eth.get_logs({\n",
    "        \"fromBlock\": block_number,\n",
    "        \"toBlock\": block_number\n",
    "    })\n",
    "\n",
    "# logs = fetch_block_logs(74934686)\n",
    "# len(logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a2d3c7f-b8c3-421a-829a-877bfffd2d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Initializing Kafka transactions...\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# delivery report for producer callback\n",
    "# -----------------------------\n",
    "def delivery_report(err, msg):\n",
    "    if err is not None:\n",
    "        print(f\"‚ùå Delivery failed: {err}\")\n",
    "    else:\n",
    "        print(\n",
    "            f\"‚úÖ Delivered to {msg.topic()} \"\n",
    "            f\"[{msg.partition()}] @ {msg.offset()}\"\n",
    "        )\n",
    "\n",
    "# -----------------------------\n",
    "# Producer initialization\n",
    "# -----------------------------\n",
    "producer = Producer({\n",
    "    \"bootstrap.servers\": KAFKA_BROKER,\n",
    "    \"enable.idempotence\": True,\n",
    "    \"acks\": \"all\",\n",
    "    \"retries\": 3,\n",
    "    \"linger.ms\": 5,\n",
    "    \"transactional.id\": TRANSACTIONAL_ID\n",
    "})\n",
    "\n",
    "print(\"üîß Initializing Kafka transactions...\")\n",
    "producer.init_transactions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b066ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñ∂Ô∏è Starting from block 74944739\n",
      "sending txs 0-9 for block 74944739 to blockchain.logs.bsc\n",
      "‚úÖ Delivered to blockchain.logs.bsc [0] @ 10939\n",
      "‚úÖ Delivered to blockchain.logs.bsc [0] @ 10940\n",
      "‚úÖ Delivered to blockchain.logs.bsc [0] @ 10941\n",
      "‚úÖ Delivered to blockchain.logs.bsc [0] @ 10942\n",
      "‚úÖ Delivered to blockchain.logs.bsc [0] @ 10943\n",
      "‚úÖ Delivered to blockchain.logs.bsc [0] @ 10944\n",
      "‚úÖ Delivered to blockchain.logs.bsc [0] @ 10945\n",
      "‚úÖ Delivered to blockchain.logs.bsc [0] @ 10946\n",
      "‚úÖ Delivered to blockchain.logs.bsc [0] @ 10947\n",
      "‚úÖ Delivered to blockchain.logs.bsc [0] @ 10948\n",
      "sending txs 10-19 for block 74944739 to blockchain.logs.bsc\n",
      "‚úÖ Delivered to blockchain.logs.bsc [0] @ 10949\n",
      "‚úÖ Delivered to blockchain.logs.bsc [0] @ 10950\n",
      "‚úÖ Delivered to blockchain.logs.bsc [0] @ 10951\n",
      "‚úÖ Delivered to blockchain.logs.bsc [0] @ 10952\n",
      "‚úÖ Delivered to blockchain.logs.bsc [0] @ 10953\n",
      "‚úÖ Delivered to blockchain.logs.bsc [0] @ 10954\n",
      "‚úÖ Delivered to blockchain.logs.bsc [0] @ 10955\n",
      "‚úÖ Delivered to blockchain.logs.bsc [0] @ 10956\n",
      "‚úÖ Delivered to blockchain.logs.bsc [0] @ 10957\n",
      "‚úÖ Delivered to blockchain.logs.bsc [0] @ 10958\n",
      "sending txs 20-29 for block 74944739 to blockchain.logs.bsc\n",
      "‚úÖ Delivered to blockchain.logs.bsc [0] @ 10959\n",
      "‚úÖ Delivered to blockchain.logs.bsc [0] @ 10960\n",
      "‚úÖ Delivered to blockchain.logs.bsc [0] @ 10961\n",
      "‚úÖ Delivered to blockchain.logs.bsc [0] @ 10962\n",
      "‚úÖ Delivered to blockchain.logs.bsc [0] @ 10963\n",
      "‚úÖ Delivered to blockchain.logs.bsc [0] @ 10964\n",
      "‚úÖ Delivered to blockchain.logs.bsc [0] @ 10965\n",
      "‚úÖ Delivered to blockchain.logs.bsc [0] @ 10966\n",
      "‚úÖ Delivered to blockchain.logs.bsc [0] @ 10967\n",
      "‚úÖ Delivered to blockchain.logs.bsc [0] @ 10968\n",
      "sending txs 30-39 for block 74944739 to blockchain.logs.bsc\n",
      "‚úÖ Delivered to blockchain.logs.bsc [0] @ 10969\n",
      "‚úÖ Delivered to blockchain.logs.bsc [0] @ 10970\n",
      "‚úÖ Delivered to blockchain.logs.bsc [0] @ 10971\n",
      "‚úÖ Delivered to blockchain.logs.bsc [0] @ 10972\n",
      "‚úÖ Delivered to blockchain.logs.bsc [0] @ 10973\n",
      "‚úÖ Delivered to blockchain.logs.bsc [0] @ 10974\n",
      "‚úÖ Delivered to blockchain.logs.bsc [0] @ 10975\n",
      "‚úÖ Delivered to blockchain.logs.bsc [0] @ 10976\n",
      "‚úÖ Delivered to blockchain.logs.bsc [0] @ 10977\n",
      "‚úÖ Delivered to blockchain.logs.bsc [0] @ 10978\n",
      "sending txs 40-49 for block 74944739 to blockchain.logs.bsc\n",
      "‚úÖ Delivered to blockchain.logs.bsc [0] @ 10979\n",
      "‚úÖ Delivered to blockchain.logs.bsc [0] @ 10980\n",
      "‚úÖ Delivered to blockchain.logs.bsc [0] @ 10981\n",
      "‚úÖ Delivered to blockchain.logs.bsc [0] @ 10982\n",
      "‚úÖ Delivered to blockchain.logs.bsc [0] @ 10983\n",
      "‚úÖ Delivered to blockchain.logs.bsc [0] @ 10984\n",
      "‚úÖ Delivered to blockchain.logs.bsc [0] @ 10985\n",
      "‚úÖ Delivered to blockchain.logs.bsc [0] @ 10986\n",
      "‚úÖ Delivered to blockchain.logs.bsc [0] @ 10987\n",
      "‚úÖ Delivered to blockchain.logs.bsc [0] @ 10988\n",
      "sending txs 50-59 for block 74944739 to blockchain.logs.bsc\n",
      "‚úÖ Delivered to blockchain.logs.bsc [0] @ 10989\n",
      "‚úÖ Delivered to blockchain.logs.bsc [0] @ 10990\n",
      "‚úÖ Delivered to blockchain.logs.bsc [0] @ 10991\n",
      "‚úÖ Delivered to blockchain.logs.bsc [0] @ 10992\n",
      "‚úÖ Delivered to blockchain.logs.bsc [0] @ 10993\n",
      "‚úÖ Delivered to blockchain.logs.bsc [0] @ 10994\n",
      "‚úÖ Delivered to blockchain.logs.bsc [0] @ 10995\n",
      "‚úÖ Delivered to blockchain.logs.bsc [0] @ 10996\n",
      "‚úÖ Delivered to blockchain.logs.bsc [0] @ 10997\n",
      "‚úÖ Delivered to blockchain.logs.bsc [0] @ 10998\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 138\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# Entrypoint\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 138\u001b[0m     \u001b[43mfetch_and_push\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[31], line 66\u001b[0m, in \u001b[0;36mfetch_and_push\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m     tx_record \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     49\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock_height\u001b[39m\u001b[38;5;124m\"\u001b[39m: bn,\n\u001b[1;32m     50\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjob_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: JOB_NAME,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtx_index\u001b[39m\u001b[38;5;124m\"\u001b[39m: idx\n\u001b[1;32m     55\u001b[0m     }\n\u001b[1;32m     57\u001b[0m     producer\u001b[38;5;241m.\u001b[39mproduce(\n\u001b[1;32m     58\u001b[0m         topic\u001b[38;5;241m=\u001b[39mBLOCKS_TOPIC,\n\u001b[1;32m     59\u001b[0m         key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m         on_delivery\u001b[38;5;241m=\u001b[39mdelivery_report,\n\u001b[1;32m     65\u001b[0m     )\n\u001b[0;32m---> 66\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msending txs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_idx\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for block \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mBLOCKS_TOPIC\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     68\u001b[0m producer\u001b[38;5;241m.\u001b[39mpoll(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# ÊØèÊâπ poll ‰∏ÄÊ¨°ÔºåÈáäÊîæÂÜÖÂ≠ò\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Main function (Kafka State + Exactly-once, lbatched splitting of logs)\n",
    "# -----------------------------\n",
    "\n",
    "def fetch_and_push():\n",
    "    \n",
    "    last_state = load_last_state(JOB_NAME)\n",
    "    last_block = last_state[\"checkpoint\"]\n",
    "    if last_block is None:\n",
    "        last_block = w3.eth.block_number - 1\n",
    "\n",
    "    print(f\"‚ñ∂Ô∏è Starting from block {last_block + 1}\", flush=True)\n",
    "\n",
    "    while True:\n",
    "        latest_block = w3.eth.block_number\n",
    "        if last_block >= latest_block:\n",
    "            time.sleep(POLL_INTERVAL)\n",
    "            continue\n",
    "\n",
    "        batch_end = min(last_block + POLL_BATCH_SIZE, latest_block)\n",
    "\n",
    "        try:\n",
    "            # üîê Kafka Transaction\n",
    "            producer.begin_transaction()\n",
    "\n",
    "            # 1Ô∏è‚É£ produce logs (split each block's logs into batches for sending)\n",
    "            for bn in range(last_block + 1, batch_end + 1):\n",
    "                block_logs = fetch_block_logs(bn)\n",
    "                if block_logs is None:\n",
    "                    raise RuntimeError(f\"block logs {bn} fetch failed\")\n",
    "\n",
    "                block_logs_safe = to_json_safe(block_logs)  # Convert to serializable\n",
    "                if isinstance(block_logs_safe, dict):\n",
    "                    transactions = block_logs_safe.get(\"transactions\", [block_logs_safe])\n",
    "                elif isinstance(block_logs_safe, list):\n",
    "                    transactions = block_logs_safe\n",
    "                else:\n",
    "                    raise RuntimeError(f\"Unexpected type for block_logs: {type(block_logs_safe)}\")\n",
    "\n",
    "\n",
    "                total_tx = len(transactions)\n",
    "                for start_idx in range(0, total_tx, BATCH_TX_SIZE):\n",
    "                    end_idx = min(start_idx + BATCH_TX_SIZE, total_tx)\n",
    "                    batch_tx = transactions[start_idx:end_idx]\n",
    "\n",
    "                    for idx, tx in enumerate(batch_tx, start=start_idx):\n",
    "                        tx_record = {\n",
    "                            \"block_height\": bn,\n",
    "                            \"job_name\": JOB_NAME,\n",
    "                            \"run_id\": RUN_ID,\n",
    "                            \"inserted_at\": current_utctime(),\n",
    "                            \"raw\": json.dumps(tx),\n",
    "                            \"tx_index\": idx\n",
    "                        }\n",
    "\n",
    "                        producer.produce(\n",
    "                            topic=BLOCKS_TOPIC,\n",
    "                            key=f\"{bn}-{idx}\",\n",
    "                            value=blocks_value_serializer(\n",
    "                                tx_record,\n",
    "                                SerializationContext(BLOCKS_TOPIC, MessageField.VALUE)\n",
    "                            ),\n",
    "                            on_delivery=delivery_report,\n",
    "                        )\n",
    "                    print(f\"sending txs {start_idx}-{end_idx-1} for block {bn} to {BLOCKS_TOPIC}\")\n",
    "                    producer.poll(0)  # Poll once per batch to free memory\n",
    "\n",
    "            # 2Ô∏è‚É£ produce state (single write)\n",
    "            state_record = {\n",
    "                \"job_name\": JOB_NAME,\n",
    "                \"run_id\": RUN_ID,\n",
    "                \"range\": {\n",
    "                    \"start\": last_block,\n",
    "                    \"end\": batch_end\n",
    "                },\n",
    "                \"checkpoint\": batch_end,\n",
    "                \"status\": \"running\",\n",
    "                \"inserted_at\": current_utctime()\n",
    "            }\n",
    "\n",
    "            producer.produce(\n",
    "                STATE_TOPIC,\n",
    "                key=JOB_NAME,\n",
    "                value=state_value_serializer(\n",
    "                    state_record,\n",
    "                    SerializationContext(STATE_TOPIC, MessageField.VALUE)\n",
    "                ),\n",
    "                on_delivery=delivery_report,\n",
    "            )\n",
    "\n",
    "            producer.poll(0)\n",
    "            # commit transactionÔºàlogs + stateÔºâ\n",
    "            producer.commit_transaction()\n",
    "\n",
    "            last_block = batch_end\n",
    "            print(f\"‚úÖ committed blocks up to {last_block}\", flush=True)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"üî• transaction failed, aborting: {e}\", flush=True)\n",
    "            try:\n",
    "                producer.abort_transaction()\n",
    "            except Exception as abort_err:\n",
    "                print(f\"Abort transaction failed: {abort_err}\")\n",
    "\n",
    "            # normal write for failed status\n",
    "            failed_state = {\n",
    "                \"job_name\": JOB_NAME,\n",
    "                \"run_id\": RUN_ID,\n",
    "                \"range\": {\n",
    "                    \"start\": last_block,\n",
    "                    \"end\": batch_end\n",
    "                },\n",
    "                \"checkpoint\": last_block - 1,\n",
    "                \"status\": \"failed\",\n",
    "                \"inserted_at\": current_utctime()\n",
    "            }\n",
    "\n",
    "            producer.produce(\n",
    "                STATE_TOPIC,\n",
    "                key=JOB_NAME,\n",
    "                value=state_value_serializer(\n",
    "                    failed_state,\n",
    "                    SerializationContext(STATE_TOPIC, MessageField.VALUE)\n",
    "                ),\n",
    "                on_delivery=delivery_report,\n",
    "            )\n",
    "\n",
    "            producer.flush()\n",
    "            raise\n",
    "\n",
    "        time.sleep(POLL_INTERVAL)\n",
    "\n",
    "\n",
    "# Entrypoint\n",
    "if __name__ == \"__main__\":\n",
    "    fetch_and_push()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9168216e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Main function \n",
    "# - Kafka State + Exactly-once, batched splitting of logs\n",
    "# -----------------------------\n",
    "\n",
    "def fetch_and_push():\n",
    "    \n",
    "    last_state = load_last_state(JOB_NAME)\n",
    "    last_block = last_state[\"checkpoint\"]\n",
    "    if last_block is None:\n",
    "        last_block = w3.eth.block_number - 1\n",
    "\n",
    "    print(f\"‚ñ∂Ô∏è Starting from block {last_block + 1}\", flush=True)\n",
    "\n",
    "    while True:\n",
    "        latest_block = w3.eth.block_number\n",
    "        if last_block >= latest_block:\n",
    "            time.sleep(POLL_INTERVAL)\n",
    "            continue\n",
    "\n",
    "        batch_end = min(last_block + BATCH_SIZE, latest_block)\n",
    "\n",
    "        try:\n",
    "            # üîê Kafka Transaction\n",
    "            producer.begin_transaction()\n",
    "\n",
    "            # 1Ô∏è‚É£ produce logs (split each block's logs into batches for sending)\n",
    "            for bn in range(last_block + 1, batch_end + 1):\n",
    "                block_logs = fetch_block_logs(bn)\n",
    "                if block_logs is None:\n",
    "                    raise RuntimeError(f\"block logs {bn} fetch failed\")\n",
    "\n",
    "                block_logs_safe = to_json_safe(block_logs)  # Convert to serializable\n",
    "                if isinstance(block_logs_safe, dict):\n",
    "                    transactions = block_logs_safe.get(\"transactions\", [block_logs_safe])\n",
    "                elif isinstance(block_logs_safe, list):\n",
    "                    transactions = block_logs_safe\n",
    "                else:\n",
    "                    raise RuntimeError(f\"Unexpected type for block_logs: {type(block_logs_safe)}\")\n",
    "\n",
    "                total_tx = len(transactions)\n",
    "                for start_idx in range(0, total_tx, BATCH_TX_SIZE):\n",
    "                    end_idx = min(start_idx + BATCH_TX_SIZE, total_tx)\n",
    "                    batch_tx = transactions[start_idx:end_idx]\n",
    "\n",
    "                    for idx, tx in enumerate(batch_tx, start=start_idx):\n",
    "                        tx_record = {\n",
    "                            \"block_height\": bn,\n",
    "                            \"job_name\": JOB_NAME,\n",
    "                            \"run_id\": RUN_ID,\n",
    "                            \"inserted_at\": current_utctime(),\n",
    "                            \"raw\": json.dumps(tx),\n",
    "                            \"tx_index\": idx\n",
    "                        }\n",
    "\n",
    "                        producer.produce(\n",
    "                            topic=BLOCKS_TOPIC,\n",
    "                            key=f\"{bn}-{idx}\",\n",
    "                            value=blocks_value_serializer(\n",
    "                                tx_record,\n",
    "                                SerializationContext(BLOCKS_TOPIC, MessageField.VALUE)\n",
    "                            ),\n",
    "                            on_delivery=delivery_report,\n",
    "                        )\n",
    "                \n",
    "                    producer.poll(0)  # Poll once per batch to free memory\n",
    "                print(f\"sending txs {start_idx}-{end_idx-1} for block {bn} to {BLOCKS_TOPIC}\")\n",
    "                \n",
    "            # 2Ô∏è‚É£ produce state (single write)\n",
    "            state_record = {\n",
    "                \"job_name\": JOB_NAME,\n",
    "                \"run_id\": RUN_ID,\n",
    "                \"range\": {\n",
    "                    \"start\": last_block + 1,\n",
    "                    \"end\": batch_end\n",
    "                },\n",
    "                \"checkpoint\": batch_end,\n",
    "                \"status\": \"running\",\n",
    "                \"inserted_at\": current_utctime()\n",
    "            }\n",
    "\n",
    "            producer.produce(\n",
    "                STATE_TOPIC,\n",
    "                key=JOB_NAME,\n",
    "                value=state_value_serializer(\n",
    "                    state_record,\n",
    "                    SerializationContext(STATE_TOPIC, MessageField.VALUE)\n",
    "                ),\n",
    "                on_delivery=delivery_report,\n",
    "            )\n",
    "\n",
    "            producer.poll(0)\n",
    "            # commit transactionÔºàlogs + stateÔºâ\n",
    "            producer.commit_transaction()\n",
    "\n",
    "            last_block = batch_end\n",
    "            print(f\"‚úÖ committed blocks up to {last_block}\", flush=True)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"üî• transaction failed, aborting: {e}\", flush=True)\n",
    "            try:\n",
    "                producer.abort_transaction()\n",
    "            except Exception as abort_err:\n",
    "                print(f\"Abort transaction failed: {abort_err}\")\n",
    "\n",
    "            # normal write for failed status\n",
    "            failed_state = {\n",
    "                \"job_name\": JOB_NAME,\n",
    "                \"run_id\": RUN_ID,\n",
    "                \"range\": {\n",
    "                    \"start\": last_block,\n",
    "                    \"end\": batch_end\n",
    "                },\n",
    "                \"checkpoint\": last_block - 1,\n",
    "                \"status\": \"failed\",\n",
    "                \"inserted_at\": current_utctime()\n",
    "            }\n",
    "\n",
    "            producer.produce(\n",
    "                STATE_TOPIC,\n",
    "                key=JOB_NAME,\n",
    "                value=state_value_serializer(\n",
    "                    failed_state,\n",
    "                    SerializationContext(STATE_TOPIC, MessageField.VALUE)\n",
    "                ),\n",
    "                on_delivery=delivery_report,\n",
    "            )\n",
    "\n",
    "            producer.flush()\n",
    "            raise\n",
    "\n",
    "        time.sleep(POLL_INTERVAL)\n",
    "\n",
    "\n",
    "# Entrypoint\n",
    "if __name__ == \"__main__\":\n",
    "    fetch_and_push()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
