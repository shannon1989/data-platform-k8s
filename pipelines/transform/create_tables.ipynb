{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e1965af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "26/02/05 08:09:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "26/02/05 08:09:31 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'http://jupyter-pyspark-7984fd7cf7-hxv9f:4041'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spark UI address\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark.sparkContext.uiWebUrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558b7654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spark.sql(\"drop table bronze.kafka_ingestion_state\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bff1abaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS bronze.kafka_ingestion_state (\n",
    "    -- ========= 核心 checkpoint =========\n",
    "    checkpoint_block        BIGINT      COMMENT '已成功处理并提交的最新区块高度',\n",
    "\n",
    "    -- ========= 运行实例(Pod) =========\n",
    "    producer_pod_name       STRING      COMMENT '执行 ingestion 的 Pod 名称',\n",
    "    producer_pod_uid        STRING      COMMENT '执行 ingestion 的 Pod UID(唯一实例标识)',\n",
    "\n",
    "    -- ========= 本次运行上下文 =========\n",
    "    run_id                  STRING      COMMENT '本次 ingestion 运行的唯一 ID',\n",
    "    run_mode                STRING      COMMENT '运行模式(realtime / checkpoint_resume / backfill / chain_head_resume)',\n",
    "    run_start_block         BIGINT      COMMENT '本次运行开始处理的区块高度',\n",
    "    run_started_at          TIMESTAMP   COMMENT '本次运行启动时间(UTC)',\n",
    "    \n",
    "    -- ========= Kafka 元数据 =========\n",
    "    kafka_key           STRING      COMMENT 'Kafka key',\n",
    "    kafka_topic         STRING      COMMENT 'Kafka topic',\n",
    "    kafka_partition     INT         COMMENT 'Kafka partition',\n",
    "    kafka_offset        BIGINT      COMMENT 'Kafka offset(全局顺序基准)',\n",
    "    kafka_timestamp     TIMESTAMP   COMMENT 'Kafka 消息时间',\n",
    "    kafka_date          DATE        COMMENT 'Kafka 消息日期',\n",
    "    \n",
    "    -- ========= 状态记录元信息 =========\n",
    "    state_updated_at        TIMESTAMP   COMMENT '该状态记录写入 Iceberg 的时间'\n",
    "    \n",
    ")\n",
    "USING iceberg\n",
    "PARTITIONED BY (\n",
    "    kafka_key\n",
    ")\n",
    "TBLPROPERTIES (\n",
    "    'format-version' = '2',\n",
    "    'write.metadata.delete-after-commit.enabled' = 'true',\n",
    "    'write.metadata.previous-versions-max' = '10'\n",
    ")\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df9fb911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bronze layer\n",
    "# bsc_mainnet_transactions\n",
    "spark.sql(\"\"\"\n",
    "  CREATE TABLE IF NOT EXISTS bronze.bsc_mainnet_transactions (\n",
    "      -- ========= 业务字段 =========\n",
    "      block_height        BIGINT      COMMENT '区块高度',\n",
    "      job_name            STRING      COMMENT '写入作业名(backfill / realtime)',\n",
    "      run_id              STRING      COMMENT 'Spark Streaming runId',   \n",
    "      raw                 STRING      COMMENT '原始 JSON 日志(Kafka value)',\n",
    "\n",
    "      -- ========= Kafka 元数据 =========\n",
    "      kafka_topic         STRING      COMMENT 'Kafka topic',\n",
    "      kafka_partition     INT         COMMENT 'Kafka partition',\n",
    "      kafka_offset        BIGINT      COMMENT 'Kafka offset(全局顺序基准)',\n",
    "      kafka_timestamp     TIMESTAMP   COMMENT 'Kafka 消息时间',\n",
    "      kafka_date          DATE        COMMENT 'Kafka 消息日期'\n",
    "  )\n",
    "  USING iceberg\n",
    "  PARTITIONED BY (\n",
    "      kafka_date\n",
    "  )\n",
    "  TBLPROPERTIES (\n",
    "      'format-version' = '2',\n",
    "      'write.metadata.delete-after-commit.enabled' = 'true',\n",
    "      'write.metadata.previous-versions-max' = '20'\n",
    "  )\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "183405c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/02/04 05:25:20 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Silver layer\n",
    "# bsc_mainnet_transactions\n",
    "spark.sql(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS silver.bsc_mainnet_transactions (\n",
    "\n",
    "    -- ========= 区块 / 作业元数据 =========\n",
    "    block_height        BIGINT      COMMENT '区块高度',\n",
    "    job_name            STRING      COMMENT '写入作业名(backfill / realtime)',\n",
    "    run_id              STRING      COMMENT 'Spark Streaming runId',\n",
    "\n",
    "    -- ========= Kafka 元数据 =========\n",
    "    kafka_topic         STRING      COMMENT 'Kafka topic',\n",
    "    kafka_partition     INT         COMMENT 'Kafka partition',\n",
    "    kafka_offset        BIGINT      COMMENT 'Kafka offset(全局顺序基准)',\n",
    "    kafka_timestamp     TIMESTAMP   COMMENT 'Kafka 消息时间',\n",
    "    kafka_date          DATE        COMMENT 'Kafka 消息日期',\n",
    "\n",
    "    -- ========= 交易基础信息 =========\n",
    "    tx_hash             STRING      COMMENT '交易哈希',\n",
    "    block_hash          STRING      COMMENT '区块哈希',\n",
    "    block_number        BIGINT      COMMENT '区块号',\n",
    "    tx_index            INT         COMMENT '交易在区块内的索引',\n",
    "    nonce               BIGINT      COMMENT '发送方交易序号',\n",
    "\n",
    "    from_address        STRING      COMMENT '发送方地址',\n",
    "    to_address          STRING      COMMENT '接收方地址(EOA 或合约)',\n",
    "\n",
    "    -- ========= 交易数值 / Gas =========\n",
    "    value_wei           DECIMAL(38,0) COMMENT '转账金额(Wei)',\n",
    "    gas_limit           BIGINT      COMMENT 'Gas limit',\n",
    "    gas_price           BIGINT      COMMENT 'Gas price(legacy)',\n",
    "    max_fee_per_gas     BIGINT      COMMENT 'EIP-1559 max fee per gas',\n",
    "    max_priority_fee_per_gas BIGINT COMMENT 'EIP-1559 priority fee',\n",
    "\n",
    "    -- ========= 交易类型 / 链信息 =========\n",
    "    tx_type             STRING      COMMENT '交易类型(legacy / 1559 / 2930)',\n",
    "    chain_id            INT         COMMENT '链 ID',\n",
    "\n",
    "    -- ========= 交易签名 =========\n",
    "    sig_v               STRING      COMMENT '签名参数 v',\n",
    "    sig_r               STRING      COMMENT '签名参数 r',\n",
    "    sig_s               STRING      COMMENT '签名参数 s',\n",
    "    y_parity            STRING      COMMENT 'EIP-1559 yParity',\n",
    "\n",
    "    -- ========= Input 简化分析字段 =========\n",
    "    input_data          STRING      COMMENT '原始 input calldata(完整保留)',\n",
    "    has_input           BOOLEAN     COMMENT '是否包含非空 input',\n",
    "    method_id           STRING      COMMENT '方法选择器(method_id, 前4字节)',\n",
    "    input_length        INT         COMMENT 'Input 字符长度',\n",
    "    input_words         DOUBLE      COMMENT 'Input 参数 word 数量(32 bytes)',\n",
    "    input_hash          STRING      COMMENT 'Input payload 哈希(sha256)',\n",
    "    is_proxy_like       BOOLEAN     COMMENT '是否疑似 proxy / delegatecall 模式交易',\n",
    "    \n",
    "    -- ========= 其他分析字段 =========\n",
    "    tx_kind             STRING      COMMENT '行为类型',\n",
    "    is_contract_call    BOOLEAN     COMMENT '是否调用合约',\n",
    "    fee_model           STRING      COMMENT 'gas 模型'\n",
    "\n",
    ")\n",
    "USING iceberg\n",
    "PARTITIONED BY (\n",
    "    kafka_date\n",
    ")\n",
    "TBLPROPERTIES (\n",
    "    'format-version' = '2',\n",
    "    'write.metadata.delete-after-commit.enabled' = 'true',\n",
    "    'write.metadata.previous-versions-max' = '20'\n",
    ")\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e275266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bronze layer\n",
    "spark.sql(\"\"\"\n",
    "  CREATE TABLE IF NOT EXISTS bronze.bsc_mainnet_logs (\n",
    "      -- ========= 业务字段 =========\n",
    "      block_height        BIGINT      COMMENT '区块高度',\n",
    "      job_name            STRING      COMMENT '写入作业名(backfill / realtime)',\n",
    "      run_id              STRING      COMMENT 'Spark Streaming runId',\n",
    "      inserted_at         TIMESTAMP   COMMENT '写入 Iceberg 的时间',\n",
    "      inserted_date       DATE        COMMENT '写入 Iceberg 的日期',\n",
    "      raw                 STRING      COMMENT '原始 JSON 日志(Kafka value)',\n",
    "\n",
    "      -- ========= Kafka 元数据(关键) =========\n",
    "      kafka_topic         STRING      COMMENT 'Kafka topic',\n",
    "      kafka_partition     INT         COMMENT 'Kafka partition',\n",
    "      kafka_offset        BIGINT      COMMENT 'Kafka offset(全局顺序基准)',\n",
    "      kafka_timestamp     TIMESTAMP   COMMENT 'Kafka 消息时间'\n",
    "  )\n",
    "  USING iceberg\n",
    "  PARTITIONED BY (\n",
    "      inserted_date\n",
    "  )\n",
    "  TBLPROPERTIES (\n",
    "      'format-version' = '2',\n",
    "      'write.metadata.delete-after-commit.enabled' = 'true',\n",
    "      'write.metadata.previous-versions-max' = '20'\n",
    "  )\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5ee19468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bronze layer\n",
    "spark.sql(\"\"\"\n",
    "  CREATE TABLE IF NOT EXISTS bronze.base_mainnet_logs (\n",
    "      -- ========= 业务字段 =========\n",
    "      block_height        BIGINT      COMMENT '区块高度',\n",
    "      job_name            STRING      COMMENT '写入作业名(backfill / realtime)',\n",
    "      run_id              STRING      COMMENT 'Spark Streaming runId',\n",
    "      inserted_at         TIMESTAMP   COMMENT '写入 Iceberg 的时间',\n",
    "      inserted_date       DATE        COMMENT '写入 Iceberg 的日期',\n",
    "      raw                 STRING      COMMENT '原始 JSON 日志(Kafka value)',\n",
    "\n",
    "      -- ========= Kafka 元数据(关键) =========\n",
    "      kafka_topic         STRING      COMMENT 'Kafka topic',\n",
    "      kafka_partition     INT         COMMENT 'Kafka partition',\n",
    "      kafka_offset        BIGINT      COMMENT 'Kafka offset(全局顺序基准)',\n",
    "      kafka_timestamp     TIMESTAMP   COMMENT 'Kafka 消息时间'\n",
    "  )\n",
    "  USING iceberg\n",
    "  PARTITIONED BY (\n",
    "      inserted_date\n",
    "  )\n",
    "  TBLPROPERTIES (\n",
    "      'format-version' = '2',\n",
    "      'write.metadata.delete-after-commit.enabled' = 'true',\n",
    "      'write.metadata.previous-versions-max' = '20'\n",
    "  )\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0c9f47",
   "metadata": {},
   "source": [
    "## Commen query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3ff2cf75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------+------------------------------------+-----------------------+-------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+---------------+------------+-----------------------+\n",
      "|block_height|job_name     |run_id                              |inserted_at            |inserted_date|raw                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |kafka_topic         |kafka_partition|kafka_offset|kafka_timestamp        |\n",
      "+------------+-------------+------------------------------------+-----------------------+-------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+---------------+------------+-----------------------+\n",
      "|40867959    |base_realtime|3b62bfd7-52ac-4398-94dd-29f621c026c6|2026-01-16 08:41:00.557|2026-01-16   |{\"removed\": false, \"logIndex\": 996, \"transactionIndex\": 184, \"transactionHash\": \"58cd7984273e7436f93a0ad26d4011a93b0fe7faeb05999ef2bc5a5cf4f9ad7a\", \"blockHash\": \"89fff2fbeb92cd8137f72b22152c867f00cea155e33b9e1a02eb652959fa591e\", \"blockNumber\": 40867959, \"address\": \"0x827922686190790b37229fd06084350E74485b72\", \"data\": \"\", \"topics\": [\"8c5be1e5ebec7d5bd14f71427d1e84f3dd0314c0f7b2291e5b200ac8c7c3b925\", \"000000000000000000000000bf5215eede91f102f13beda4fabbdb44e9269066\", \"0000000000000000000000000000000000000000000000000000000000000000\", \"0000000000000000000000000000000000000000000000000000000002ad3566\"]}                                                                                                                                                                                                                                                                 |blockchain.logs.base|0              |56400000    |2026-01-16 08:41:00.557|\n",
      "|40867959    |base_realtime|3b62bfd7-52ac-4398-94dd-29f621c026c6|2026-01-16 08:41:00.557|2026-01-16   |{\"removed\": false, \"logIndex\": 997, \"transactionIndex\": 184, \"transactionHash\": \"58cd7984273e7436f93a0ad26d4011a93b0fe7faeb05999ef2bc5a5cf4f9ad7a\", \"blockHash\": \"89fff2fbeb92cd8137f72b22152c867f00cea155e33b9e1a02eb652959fa591e\", \"blockNumber\": 40867959, \"address\": \"0x827922686190790b37229fd06084350E74485b72\", \"data\": \"\", \"topics\": [\"ddf252ad1be2c89b69c2b068fc378daa952ba7f163c4a11628f55a4df523b3ef\", \"000000000000000000000000bf5215eede91f102f13beda4fabbdb44e9269066\", \"00000000000000000000000041b2126661c673c2bedd208cc72e85dc51a5320a\", \"0000000000000000000000000000000000000000000000000000000002ad3566\"]}                                                                                                                                                                                                                                                                 |blockchain.logs.base|0              |56400001    |2026-01-16 08:41:00.557|\n",
      "|40867959    |base_realtime|3b62bfd7-52ac-4398-94dd-29f621c026c6|2026-01-16 08:41:00.557|2026-01-16   |{\"removed\": false, \"logIndex\": 998, \"transactionIndex\": 184, \"transactionHash\": \"58cd7984273e7436f93a0ad26d4011a93b0fe7faeb05999ef2bc5a5cf4f9ad7a\", \"blockHash\": \"89fff2fbeb92cd8137f72b22152c867f00cea155e33b9e1a02eb652959fa591e\", \"blockNumber\": 40867959, \"address\": \"0x41b2126661C673C2beDd208cC72E85DC51a5320a\", \"data\": \"\", \"topics\": [\"1c8ab8c7f45390d58f58f1d655213a82cca5d12179761a87c16f098813b8f211\", \"000000000000000000000000bf5215eede91f102f13beda4fabbdb44e9269066\", \"0000000000000000000000000000000000000000000000000000000002ad3566\", \"00000000000000000000000000000000000000000000000002262844678ae412\"]}                                                                                                                                                                                                                                                                 |blockchain.logs.base|0              |56400002    |2026-01-16 08:41:00.557|\n",
      "|40867959    |base_realtime|3b62bfd7-52ac-4398-94dd-29f621c026c6|2026-01-16 08:41:00.557|2026-01-16   |{\"removed\": false, \"logIndex\": 999, \"transactionIndex\": 185, \"transactionHash\": \"bde2af865a5128b44941a9953afc5bbe80120dfc44294d7ed59974ad402973bc\", \"blockHash\": \"89fff2fbeb92cd8137f72b22152c867f00cea155e33b9e1a02eb652959fa591e\", \"blockNumber\": 40867959, \"address\": \"0x833589fCD6eDb6E08f4c7C32D4f71b54bdA02913\", \"data\": \"0000000000000000000000000000000000000000000000000000004ab8ff0355\", \"topics\": [\"8c5be1e5ebec7d5bd14f71427d1e84f3dd0314c0f7b2291e5b200ac8c7c3b925\", \"000000000000000000000000b7347330527f543ec1f0272feb6fb58d0d05f859\", \"000000000000000000000000827922686190790b37229fd06084350e74485b72\"]}                                                                                                                                                                                                                                                                     |blockchain.logs.base|0              |56400003    |2026-01-16 08:41:00.557|\n",
      "|40867959    |base_realtime|3b62bfd7-52ac-4398-94dd-29f621c026c6|2026-01-16 08:41:00.557|2026-01-16   |{\"removed\": false, \"logIndex\": 1000, \"transactionIndex\": 185, \"transactionHash\": \"bde2af865a5128b44941a9953afc5bbe80120dfc44294d7ed59974ad402973bc\", \"blockHash\": \"89fff2fbeb92cd8137f72b22152c867f00cea155e33b9e1a02eb652959fa591e\", \"blockNumber\": 40867959, \"address\": \"0xcbB7C0000aB88B473b1f5aFd9ef808440eed33Bf\", \"data\": \"000000000000000000000000000000000000000000000000000000001376756f\", \"topics\": [\"8c5be1e5ebec7d5bd14f71427d1e84f3dd0314c0f7b2291e5b200ac8c7c3b925\", \"000000000000000000000000b7347330527f543ec1f0272feb6fb58d0d05f859\", \"000000000000000000000000827922686190790b37229fd06084350e74485b72\"]}                                                                                                                                                                                                                                                                    |blockchain.logs.base|0              |56400004    |2026-01-16 08:41:00.557|\n",
      "|40867959    |base_realtime|3b62bfd7-52ac-4398-94dd-29f621c026c6|2026-01-16 08:41:00.557|2026-01-16   |{\"removed\": false, \"logIndex\": 1001, \"transactionIndex\": 185, \"transactionHash\": \"bde2af865a5128b44941a9953afc5bbe80120dfc44294d7ed59974ad402973bc\", \"blockHash\": \"89fff2fbeb92cd8137f72b22152c867f00cea155e33b9e1a02eb652959fa591e\", \"blockNumber\": 40867959, \"address\": \"0x833589fCD6eDb6E08f4c7C32D4f71b54bdA02913\", \"data\": \"00000000000000000000000000000000000000000000000000000024c123b2c1\", \"topics\": [\"ddf252ad1be2c89b69c2b068fc378daa952ba7f163c4a11628f55a4df523b3ef\", \"000000000000000000000000b7347330527f543ec1f0272feb6fb58d0d05f859\", \"0000000000000000000000004e962bb3889bf030368f56810a9c96b83cb3e778\"]}                                                                                                                                                                                                                                                                    |blockchain.logs.base|0              |56400005    |2026-01-16 08:41:00.557|\n",
      "|40867959    |base_realtime|3b62bfd7-52ac-4398-94dd-29f621c026c6|2026-01-16 08:41:00.557|2026-01-16   |{\"removed\": false, \"logIndex\": 1002, \"transactionIndex\": 185, \"transactionHash\": \"bde2af865a5128b44941a9953afc5bbe80120dfc44294d7ed59974ad402973bc\", \"blockHash\": \"89fff2fbeb92cd8137f72b22152c867f00cea155e33b9e1a02eb652959fa591e\", \"blockNumber\": 40867959, \"address\": \"0xcbB7C0000aB88B473b1f5aFd9ef808440eed33Bf\", \"data\": \"000000000000000000000000000000000000000000000000000000001376756f\", \"topics\": [\"ddf252ad1be2c89b69c2b068fc378daa952ba7f163c4a11628f55a4df523b3ef\", \"000000000000000000000000b7347330527f543ec1f0272feb6fb58d0d05f859\", \"0000000000000000000000004e962bb3889bf030368f56810a9c96b83cb3e778\"]}                                                                                                                                                                                                                                                                    |blockchain.logs.base|0              |56400006    |2026-01-16 08:41:00.557|\n",
      "|40867959    |base_realtime|3b62bfd7-52ac-4398-94dd-29f621c026c6|2026-01-16 08:41:00.557|2026-01-16   |{\"removed\": false, \"logIndex\": 1003, \"transactionIndex\": 185, \"transactionHash\": \"bde2af865a5128b44941a9953afc5bbe80120dfc44294d7ed59974ad402973bc\", \"blockHash\": \"89fff2fbeb92cd8137f72b22152c867f00cea155e33b9e1a02eb652959fa591e\", \"blockNumber\": 40867959, \"address\": \"0x4e962BB3889Bf030368F56810A9c96B83CB3E778\", \"data\": \"000000000000000000000000827922686190790b37229fd06084350e74485b72000000000000000000000000000000000000000000000000000002c4ed06bebe00000000000000000000000000000000000000000000000000000024c123b2c1000000000000000000000000000000000000000000000000000000001376756f\", \"topics\": [\"7a53080ba414158be7ec69b987b5fb7d07dee101fe85488f0853ae16239d0bde\", \"000000000000000000000000827922686190790b37229fd06084350e74485b72\", \"fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffef3a4\", \"fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffef408\"]}|blockchain.logs.base|0              |56400007    |2026-01-16 08:41:00.557|\n",
      "|40867959    |base_realtime|3b62bfd7-52ac-4398-94dd-29f621c026c6|2026-01-16 08:41:00.557|2026-01-16   |{\"removed\": false, \"logIndex\": 1004, \"transactionIndex\": 185, \"transactionHash\": \"bde2af865a5128b44941a9953afc5bbe80120dfc44294d7ed59974ad402973bc\", \"blockHash\": \"89fff2fbeb92cd8137f72b22152c867f00cea155e33b9e1a02eb652959fa591e\", \"blockNumber\": 40867959, \"address\": \"0x827922686190790b37229fd06084350E74485b72\", \"data\": \"\", \"topics\": [\"ddf252ad1be2c89b69c2b068fc378daa952ba7f163c4a11628f55a4df523b3ef\", \"0000000000000000000000000000000000000000000000000000000000000000\", \"000000000000000000000000b7347330527f543ec1f0272feb6fb58d0d05f859\", \"0000000000000000000000000000000000000000000000000000000002ad3567\"]}                                                                                                                                                                                                                                                                |blockchain.logs.base|0              |56400008    |2026-01-16 08:41:00.557|\n",
      "|40867959    |base_realtime|3b62bfd7-52ac-4398-94dd-29f621c026c6|2026-01-16 08:41:00.557|2026-01-16   |{\"removed\": false, \"logIndex\": 1005, \"transactionIndex\": 185, \"transactionHash\": \"bde2af865a5128b44941a9953afc5bbe80120dfc44294d7ed59974ad402973bc\", \"blockHash\": \"89fff2fbeb92cd8137f72b22152c867f00cea155e33b9e1a02eb652959fa591e\", \"blockNumber\": 40867959, \"address\": \"0x827922686190790b37229fd06084350E74485b72\", \"data\": \"000000000000000000000000000000000000000000000000000002c4ed06bebe00000000000000000000000000000000000000000000000000000024c123b2c1000000000000000000000000000000000000000000000000000000001376756f\", \"topics\": [\"3067048beee31b25b2f1681f88dac838c8bba36af25bfb2b7cf7473a5847e35f\", \"0000000000000000000000000000000000000000000000000000000002ad3567\"]}                                                                                                                                                                                                        |blockchain.logs.base|0              |56400009    |2026-01-16 08:41:00.557|\n",
      "+------------+-------------+------------------------------------+-----------------------+-------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+---------------+------------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# drop table -> delete files\n",
    "# spark.conf.get(\"spark.sql.catalog.spark_catalog.purge\", \"true\")\n",
    "# spark.sql(\"\"\"drop table bronze.base_mainnet_logs\"\"\").show(truncate=False)\n",
    "\n",
    "\n",
    "# spark.sql(\"describe table bronze.base_mainnet_logs\").show()\n",
    "# spark.sql(\"select count(1) from bronze.base_mainnet_logs\").show()\n",
    "# spark.sql(\"\"\"select max(block_height) from bronze.base_mainnet_logs\"\"\").show(truncate=False)\n",
    "# spark.sql(\"\"\"SELECT summary FROM bronze.base_mainnet_logs.snapshots ORDER BY committed_at DESC LIMIT 10\"\"\").show(truncate=False)\n",
    "spark.sql(\"\"\"select * from bronze.base_mainnet_logs limit 10\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e1fee9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------+\n",
      "|max(block_height)|max(kafka_offset)|\n",
      "+-----------------+-----------------+\n",
      "|40877456         |67212993         |\n",
      "+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    select \n",
    "        max(block_height), \n",
    "        max(kafka_offset)\n",
    "    from bronze.base_mainnet_logs\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965e5a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Silver layer\n",
    "spark.sql(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS silver.base_mainnet_logs (\n",
    "    removed BOOLEAN COMMENT '是否被回滚',\n",
    "    log_index BIGINT COMMENT '在区块内的索引',\n",
    "    transaction_index BIGINT COMMENT '交易在区块内的索引',\n",
    "    transaction_hash STRING COMMENT '交易哈希',\n",
    "    block_hash STRING COMMENT '区块哈希',\n",
    "    block_number BIGINT COMMENT '区块高度',\n",
    "    address STRING COMMENT '合约地址(触发事件的合约)',\n",
    "    data STRING COMMENT 'ABI 编码后的数据(通常是 uint256 或 bytes)',\n",
    "    topics ARRAY<STRING> COMMENT '事件签名 + indexed 参数'\n",
    ")\n",
    "USING ICEBERG;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9982f654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query.stop() # stop the streaming\n",
    "\n",
    "# query.status\n",
    "# query.lastProgress\n",
    "# query.isActive\n",
    "\n",
    "# check all streaming jobs\n",
    "# spark.streams.active\n",
    "\n",
    "# 强制停止所有 Streaming(救命用)\n",
    "for q in spark.streams.active:\n",
    "    print(\"Stopping:\", q.name)\n",
    "#     q.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
