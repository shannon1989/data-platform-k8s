{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48e532f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "26/02/04 05:40:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "26/02/04 05:40:42 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "26/02/04 05:40:42 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "26/02/04 05:40:42 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "26/02/04 05:40:42 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n",
      "26/02/04 05:40:42 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"silver_bsc_transactions_incremental\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6664fa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read max offset of silver\n",
    "def get_silver_max_offset(table_name: str) -> int:\n",
    "    if not spark.catalog.tableExists(table_name):\n",
    "        return -1\n",
    "\n",
    "    row = (\n",
    "        spark.table(table_name)\n",
    "        .agg(F.max(\"kafka_offset\").alias(\"max_offset\"))\n",
    "        .collect()\n",
    "    )[0]\n",
    "\n",
    "    return row[\"max_offset\"] if row[\"max_offset\"] is not None else -1\n",
    "\n",
    "# utility function\n",
    "def hex_to_long(col):\n",
    "    return F.conv(F.regexp_replace(col, \"^0x\", \"\"), 16, 10).cast(\"long\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5472a261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Silver] current max kafka_offset = 278830\n"
     ]
    }
   ],
   "source": [
    "SILVER_TABLE = \"silver.bsc_mainnet_transactions\"\n",
    "\n",
    "silver_max_offset = get_silver_max_offset(SILVER_TABLE)\n",
    "print(f\"[Silver] current max kafka_offset = {silver_max_offset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18886c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Silver] No new bronze data, exit\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# read incremental bronze data\n",
    "BRONZE_TABLE = \"bronze.bsc_mainnet_transactions\"\n",
    "\n",
    "bronze_inc = (\n",
    "    spark.table(BRONZE_TABLE)\n",
    "    .filter(F.col(\"kafka_offset\") > silver_max_offset)\n",
    ")\n",
    "\n",
    "if bronze_inc.rdd.isEmpty():\n",
    "    print(\"[Silver] No new bronze data, exit\")\n",
    "    spark.stop()\n",
    "    exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03758e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_bronze_to_silver(df):\n",
    "\n",
    "    json_schema = StructType([\n",
    "        StructField(\"blockHash\", StringType()),\n",
    "        StructField(\"blockNumber\", StringType()),\n",
    "        StructField(\"from\", StringType()),\n",
    "        StructField(\"to\", StringType()),\n",
    "        StructField(\"nonce\", StringType()),\n",
    "        StructField(\"hash\", StringType()),\n",
    "        StructField(\"transactionIndex\", StringType()),\n",
    "        StructField(\"value\", StringType()),\n",
    "        StructField(\"gas\", StringType()),\n",
    "        StructField(\"gasPrice\", StringType()),\n",
    "        StructField(\"maxFeePerGas\", StringType()),\n",
    "        StructField(\"maxPriorityFeePerGas\", StringType()),\n",
    "        StructField(\"input\", StringType()),\n",
    "        StructField(\"type\", StringType()),\n",
    "        StructField(\"accessList\", ArrayType(\n",
    "            StructType([\n",
    "                StructField(\"address\", StringType()),\n",
    "                StructField(\"storageKeys\", ArrayType(StringType()))\n",
    "            ])\n",
    "        )),\n",
    "        StructField(\"chainId\", StringType()),\n",
    "        StructField(\"v\", StringType()),\n",
    "        StructField(\"r\", StringType()),\n",
    "        StructField(\"s\", StringType()),\n",
    "        StructField(\"yParity\", StringType()),\n",
    "    ])\n",
    "\n",
    "    parsed = (\n",
    "        df\n",
    "        .withColumn(\"tx\", F.from_json(\"raw\", json_schema))\n",
    "        .filter(F.col(\"tx.hash\").isNotNull())\n",
    "    )\n",
    "\n",
    "    silver = (\n",
    "        parsed\n",
    "        .select(\n",
    "            # Kafka & ingestion metadata\n",
    "            \"block_height\",\n",
    "            \"job_name\",\n",
    "            \"run_id\",\n",
    "            \"kafka_topic\",\n",
    "            \"kafka_partition\",\n",
    "            \"kafka_offset\",\n",
    "            \"kafka_timestamp\",\n",
    "            \"kafka_date\",\n",
    "\n",
    "            # Transaction identity\n",
    "            F.col(\"tx.hash\").alias(\"tx_hash\"),\n",
    "            F.col(\"tx.blockHash\").alias(\"block_hash\"),\n",
    "            hex_to_long(F.col(\"tx.blockNumber\")).alias(\"block_number\"),\n",
    "            hex_to_long(F.col(\"tx.transactionIndex\")).cast(\"int\").alias(\"tx_index\"),\n",
    "            hex_to_long(F.col(\"tx.nonce\")).alias(\"nonce\"),\n",
    "            F.col(\"tx.from\").alias(\"from_address\"),\n",
    "            F.col(\"tx.to\").alias(\"to_address\"),\n",
    "\n",
    "            # ---- Value & gas ----\n",
    "            hex_to_long(F.col(\"tx.value\")).cast(\"decimal(38,0)\").alias(\"value_wei\"),\n",
    "            hex_to_long(F.col(\"tx.gas\")).alias(\"gas_limit\"),\n",
    "            hex_to_long(F.col(\"tx.gasPrice\")).alias(\"gas_price\"),\n",
    "            hex_to_long(F.col(\"tx.maxFeePerGas\")).alias(\"max_fee_per_gas\"),\n",
    "            hex_to_long(F.col(\"tx.maxPriorityFeePerGas\")).alias(\"max_priority_fee_per_gas\"),\n",
    "\n",
    "            # ---- Type & chain ----\n",
    "            F.col(\"tx.type\").alias(\"tx_type\"),\n",
    "            hex_to_long(F.col(\"tx.chainId\")).cast(\"int\").alias(\"chain_id\"),\n",
    "\n",
    "            # ---- Signature ----\n",
    "            F.col(\"tx.v\").alias(\"sig_v\"),\n",
    "            F.col(\"tx.r\").alias(\"sig_r\"),\n",
    "            F.col(\"tx.s\").alias(\"sig_s\"),\n",
    "            F.col(\"tx.yParity\").alias(\"y_parity\"),\n",
    "\n",
    "            # ---- Input ----\n",
    "            F.col(\"tx.input\").alias(\"input_data\"),\n",
    "        )\n",
    "        .withColumn(\"has_input\", F.col(\"input_data\") != \"0x\")\n",
    "        .withColumn(\"method_id\", F.when(F.col(\"has_input\"), F.substring(\"input_data\", 1, 10)))\n",
    "        .withColumn(\"input_length\", F.length(\"input_data\"))\n",
    "        .withColumn(\"input_words\", (F.col(\"input_length\") - 2) / 64)\n",
    "        .withColumn(\"input_hash\", F.sha2(\"input_data\", 256))\n",
    "        .withColumn(\"is_proxy_like\", F.col(\"method_id\").isin(\"0x5c60da1b\", \"0x3659cfe6\")\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"tx_kind\",\n",
    "            F.when(F.col(\"to_address\").isNull(), \"contract_creation\")\n",
    "            .when(F.col(\"input_data\") == \"0x\", \"transfer\")\n",
    "            .otherwise(\"contract_call\")\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"is_contract_call\",\n",
    "            F.col(\"input_data\") != \"0x\"\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"fee_model\",\n",
    "            F.when(F.col(\"tx_type\") == \"0x2\", \"eip1559\")\n",
    "            .when(F.col(\"tx_type\") == \"0x1\", \"access_list\")\n",
    "            .otherwise(\"legacy\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return silver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4a34213",
   "metadata": {},
   "outputs": [],
   "source": [
    "silver_inc = transform_bronze_to_silver(bronze_inc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860fbf50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/02/04 05:56:48 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "[Stage 7:======================================================>(191 + 1) / 192]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Silver] appended 1503099 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 允许多行链式调用，不用反斜杠 \\\n",
    "(\n",
    "    silver_inc\n",
    "    .write\n",
    "    .format(\"iceberg\")\n",
    "    .mode(\"append\")\n",
    "    .saveAsTable(SILVER_TABLE)\n",
    ")\n",
    "\n",
    "print(f\"[Silver] appended {silver_inc.count()} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c9af1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# silver_inc \\\n",
    "# .write \\\n",
    "# .format(\"iceberg\") \\\n",
    "# .mode(\"append\") \\\n",
    "# .saveAsTable(SILVER_TABLE)\n",
    "\n",
    "# 等价于\n",
    "\n",
    "# (\n",
    "#     silver_inc\n",
    "#     .write\n",
    "#     .format(\"iceberg\")\n",
    "#     .mode(\"append\")\n",
    "#     .saveAsTable(SILVER_TABLE)\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
