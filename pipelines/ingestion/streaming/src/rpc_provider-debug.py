import os
import time
import random
import asyncio
import aiohttp
import uuid
from dataclasses import dataclass
from typing import NamedTuple
import itertools
from src.logging import log
from src.web3_utils import build_method_group_map
from src.metrics.runtime import get_metrics

_m = None
def m():
    global _m
    if _m is None:
        _m = get_metrics()
    return _m

# -----------------------------
# Exceptions
# -----------------------------
class RpcKeyUnavailable(Exception): pass
class RpcTemporarilyUnavailable(Exception): pass
class RpcRateLimitError(Exception): pass

# -----------------------------
# RPC Trace
# -----------------------------
@dataclass
class RpcTrace:
    method: str
    dns_ms: float | None = None
    tcp_ms: float | None = None
    http_wait_ms: float | None = None
    total_ms: float | None = None

@dataclass
class RpcTaskMeta:
    task_id: int
    submit_ts: float
    extra: dict

@dataclass
class RpcErrorResult:
    error: Exception
    rpc: str | None
    key_env: str | None
    meta: RpcTaskMeta
    wid: int


# -----------------------------
# AsyncRpcClient
# å‘é€ JSON-RPCï¼Œé‡æ‰€æœ‰ç½‘ç»œé˜¶æ®µï¼Œè¿”å› (result, trace)
# -----------------------------
class AsyncRpcClient:
    def __init__(self, timeout: int = 10):
        self.timeout = timeout

    def _build_trace_config(self, trace: RpcTrace):
        tc = aiohttp.TraceConfig()

        async def on_dns_start(_, __, ___):
            trace._dns_start = time.perf_counter()

        async def on_dns_end(_, __, ___):
            trace.dns_ms = (time.perf_counter() - trace._dns_start) * 1000

        async def on_connection_create_start(_, __, ___):
            trace._tcp_start = time.perf_counter()

        async def on_connection_create_end(_, __, ___):
            trace.tcp_ms = (time.perf_counter() - trace._tcp_start) * 1000

        async def on_request_headers_sent(_, __, ___):
            trace._http_wait_start = time.perf_counter()

        async def on_response_chunk_received(_, __, ___):
            if trace.http_wait_ms is None:
                trace.http_wait_ms = (
                    time.perf_counter() - trace._http_wait_start
                ) * 1000

        tc.on_dns_resolvehost_start.append(on_dns_start)
        tc.on_dns_resolvehost_end.append(on_dns_end)
        tc.on_connection_create_start.append(on_connection_create_start)
        tc.on_connection_create_end.append(on_connection_create_end)
        tc.on_request_headers_sent.append(on_request_headers_sent)
        tc.on_response_chunk_received.append(on_response_chunk_received)

        return tc

    async def call(self, url: str, method: str, params: list):
        
        log.debug(
            "ğŸŒ rpc_http_request",
            extra={
                "method": method,
                "url": url,
            },
        )
        
        trace = RpcTrace(method=method)
        trace_cfg = self._build_trace_config(trace)

        timeout = aiohttp.ClientTimeout(total=self.timeout)
        payload = {
            "jsonrpc": "2.0",
            "id": str(uuid.uuid4()),
            "method": method,
            "params": params,
        }

        # ç¦ç”¨ brotliï¼Œé¿å… aiohttp / brotli å…¼å®¹é—®é¢˜
        RPC_HEADERS = {
            "Content-Type": "application/json",
            "Accept": "application/json",
            "Accept-Encoding": "gzip, deflate",
        }

        start = time.perf_counter()
        async with aiohttp.ClientSession(
            timeout=timeout,
            trace_configs=[trace_cfg],
        ) as session:
            async with session.post(url,
                json=payload,
                headers=RPC_HEADERS
                ) as resp:
                if resp.status == 429:
                    raise RpcRateLimitError("HTTP 429 rate limited")
                data = await resp.json()

        trace.total_ms = (time.perf_counter() - start) * 1000

        if "error" in data:
            code = data["error"].get("code")
            if code in (-32005, -32016, -32000, 10007):
                raise RpcRateLimitError(data["error"])
            raise RuntimeError(data["error"])

        log.info(
            "âœ… rpc_http_success",
            extra={
                "method": method,
                "total_ms": round(trace.total_ms, 2),
            },
        )

        return data["result"], trace


# -----------------------------
# RpcContext
# -----------------------------
class RpcContext(NamedTuple):
    rpc: str
    key_env: str

# -----------------------------
# RPC Key Slot: æ»‘åŠ¨çª—å£é¢‘ç‡æ§åˆ¶
# -----------------------------
class RpcKeySlot:
    def __init__(self, key_env: str, min_interval: float):
        self.key_env = key_env
        self.min_interval = min_interval
        self._lock = asyncio.Lock()
        self._next_available = 0.0

    async def acquire(self):
        async with self._lock:
            now = time.monotonic()
            if now < self._next_available:
                m().rpc_key_unavailable_inc(self.key_env)
                raise RpcKeyUnavailable(self.key_env)

            self._next_available = now + self.min_interval
            return os.getenv(self.key_env)

# -----------------------------
# RPC Provider
# -----------------------------
class RpcProvider:
    def __init__(self, name, base_url, weight, key_envs=None, key_interval=1.0, base_cooldown=10, max_cooldown=300, disable_threshold=10):
        self.name = name
        self.base_url = base_url
        self.weight = weight
        
        # failure & backoff
        self.fail_count = 0
        self.cooldown_until = 0.0
        self.base_cooldown = base_cooldown
        self.max_cooldown = max_cooldown
        self.disable_threshold = disable_threshold
        self.disabled = False

        # normalize key_envs: None | str | list -> list
        if not key_envs:
            self.key_envs = []
        elif isinstance(key_envs, str):
            self.key_envs = [key_envs]
        else:
            self.key_envs = list(key_envs)
    
        self.slots = [
            RpcKeySlot(env, key_interval)
            for env in self.key_envs
        ]

        self._rr = 0


    def available(self) -> bool:
        if self.disabled:
            return False

        now = time.monotonic()
        return now >= self.cooldown_until

    def on_success(self):
        if self.fail_count > 0:
            log.info(
                "âœ… rpc_recovered",
                extra={
                    "rpc": self.name,
                    "prev_fail_count": self.fail_count,
                },
            )

        self.fail_count = 0
        self.cooldown_until = 0.0


    def on_failure(self):
        self.fail_count += 1

        # è®¡ç®—æŒ‡æ•°é€€é¿
        cooldown = min(
            self.base_cooldown * (2 ** (self.fail_count - 1)),
            self.max_cooldown,
        )

        self.cooldown_until = time.monotonic() + cooldown

        log.warning(
            "âš ï¸ rpc_failure",
            extra={
                "rpc": self.name,
                "fail_count": self.fail_count,
                "cooldown_sec": cooldown,
            },
        )

        # è¿ç»­å¤±è´¥è¿‡å¤š â†’ æ°¸ä¹…ç¦ç”¨
        if self.fail_count >= self.disable_threshold:
            self.disabled = True
            log.error(
                "ğŸ’€ rpc_disabled_permanently",
                extra={
                    "rpc": self.name,
                    "fail_count": self.fail_count,
                },
            )



    async def acquire_slot(self):
        if not self.slots:
            return self.base_url, "public"

        for _ in range(len(self.slots)):
            slot = self.slots[self._rr]
            self._rr = (self._rr + 1) % len(self.slots)
            try:
                key = await slot.acquire()
                return f"{self.base_url}/{key}", slot.key_env
            except RpcKeyUnavailable:
                continue

        raise RpcKeyUnavailable(self.name)



# -----------------------------
# RpcPool
# -----------------------------
class RpcPool:
    def __init__(self, providers):
        self.providers = providers
        
    def pick_providers(self):
        """
        æ ¹æ® weight ç”Ÿæˆä¸€ä¸ª provider å°è¯•é¡ºåº (weightè¶Šå¤§, è¶Šå…ˆå°è¯•è¿™ä¸ªprovider)
        """
        candidates = []

        for p in self.providers:
            if not p.available():
                continue
            candidates.extend([p] * p.weight)

        random.shuffle(candidates)
        return candidates
    
    @classmethod
    def grouped_from_config(cls, rpc_configs: dict, chain: str) -> "GroupedRpcPool":
        chain_cfg = rpc_configs["chains"][chain]
    
        method_group_map = build_method_group_map(chain_cfg)
    
        pools: dict[str, RpcPool] = {}
    
        for cfg in chain_cfg.get("providers", []):
            if not cfg.get("enabled", True):
                continue
    
            groups = cfg.get("method_groups", [])
            if isinstance(groups, str):
                groups = [groups]
    
            for g in groups:
                pools.setdefault(g, []).append(
                    RpcProvider(
                        name=cfg["name"],
                        base_url=cfg["base_url"],
                        weight=int(cfg.get("weight", 1)),
                        key_envs=cfg.get("api_keys_env"),
                        key_interval=float(cfg.get("key_interval", 1.0)),
                    )
                )
    
        rpc_pools = {
            g: RpcPool(providers)
            for g, providers in pools.items()
        }
    
        return GroupedRpcPool(rpc_pools, method_group_map)


# æŒ‰ method_group æ„å»ºå¤šä¸ª RpcPool
class GroupedRpcPool:
    def __init__(self, pools: dict[str, RpcPool], method_group_map: dict[str, str]):
        self.pools = pools
        self.method_group_map = method_group_map

    def pool_for_method(self, method: str) -> RpcPool:
        group = self.method_group_map.get(method)
        if not group:
            log.warning("method_group_not_found", extra={"method": method})
            group = "heavy"

        pool = self.pools.get(group)
        if not pool:
            raise RuntimeError(f"No RPC pool for method_group: {group}")

        return pool


class Web3AsyncRouter:
    def __init__(self, grouped_pool: GroupedRpcPool, client):
        self.grouped_pool = grouped_pool
        self.client = client

    async def call_once(self, method, params):
        
        pool = self.grouped_pool.pool_for_method(method)
        providers = pool.pick_providers()

        log.debug(
            "ğŸ”€ rpc_call_once_start",
            extra={
                "method": method,
                "params": params,
                "provider_count": len(providers),
            },
        )

        for p in providers:
            
            log.debug(
                "â¡ï¸ rpc_try_provider",
                extra={
                    "rpc": p.name,
                    "available": p.available(),
                    "fail_count": p.fail_count,
                },
            )
            
            if not p.available():
                continue

            try:
                url, key_env = await p.acquire_slot()
            except RpcKeyUnavailable:
                continue

            try:
                result, trace = await self.client.call(url, method, params)

                p.on_success()
                return result, p.name, key_env, trace

            except RpcRateLimitError as e:
                # ğŸš¨ å¼ºå¤±è´¥ï¼šç›´æ¥æŒ‡æ•°é€€é¿
                p.on_failure()
                continue

            except (TimeoutError, asyncio.TimeoutError) as e:
                # â±ï¸ è½¯å¤±è´¥ï¼šä¹Ÿè®¡å…¥æŒ‡æ•°é€€é¿ï¼ˆå¾ˆé‡è¦ï¼‰
                p.on_failure()
                continue

            except Exception as e:
                # âŒ æœªçŸ¥é”™è¯¯ï¼šè§†ä¸ºå¤±è´¥
                p.on_failure()

                m().rpc_failed_inc(provider=p.name, key=key_env)
                log.warning(
                    "âš ï¸ rpc_call_error",
                    extra={
                        "provider": p.name,
                        "key": key_env,
                        "error_type": type(e).__name__,
                        "error": str(e),
                    },
                )
                raise

        # æ‰€æœ‰ provider éƒ½ä¸å¯ç”¨
        # raise RpcTemporarilyUnavailable()
    

    async def get_latest_block(self) -> int:
        result, rpc, key_env, trace = await self.call_once(
            "eth_blockNumber",
            []
        )
        log.info(
            "ğŸ“¦ get_latest_block",
            extra={
                "rpc": rpc,
                "key_env": key_env,
                # "method": "eth_blockNumber",
                "latest_block": int(result, 16)
            },
        )
        return int(result, 16)


_task_seq = itertools.count(1)
_STOP = object()

class AsyncRpcScheduler:
    def __init__(
        self,
        router,
        max_workers: int,
        max_queue: int,
        max_inflight: int,
    ):
        self.router = router
        self.queue = asyncio.Queue(max_queue)
        self.inflight = asyncio.Semaphore(max_inflight)
        self.workers = []
        self._closed = False

        for wid in range(max_workers):
            task = asyncio.create_task(self._dispatcher_loop(wid))
            self.workers.append(task)

    async def submit(
        self,
        method: str, 
        params: list,
        *,
        meta: dict | None = None,
    ):
        if self._closed:
            raise RuntimeError("Scheduler already closed")

        loop = asyncio.get_running_loop()
        fut = loop.create_future()

        task_meta = RpcTaskMeta(
            task_id=next(_task_seq),
            submit_ts=time.time(),
            extra=meta or {},   # ğŸ”¥ ä¸šåŠ¡ meta
        )

        await self.queue.put((method, params, fut, task_meta))

        log.info(
            "ğŸ“¤ rpc_task_submitted",
            extra={
                "task_id": task_meta.task_id,
                "method": method,
                "queue_size": self.queue.qsize(),
                "meta": task_meta.extra,
            },
        )

        m().rpc_submitted_inc()
        m().rpc_queue_size_set(self.queue.qsize())
        
        return await fut

    async def _dispatcher_loop(self, wid: int):
        log.info("rpc_dispatcher_started", extra={"worker": wid})

        while True:
            try:
                item = await self.queue.get()

                # ğŸ”¥ å…³é”®ï¼šæ”¶åˆ°é€€å‡ºä¿¡å·
                if item is _STOP:
                    self.queue.task_done()
                    break
                
                method, params, fut, meta = item
            except asyncio.CancelledError:
                break

            dispatch_ts = time.time()

            queue_wait_ms = (dispatch_ts - meta.submit_ts) * 1000
            m().rpc_queue_wait_observe(queue_wait_ms)
            m().rpc_queue_size_set(self.queue.qsize())
            
            log.debug(
                "ğŸ§­ rpc_dispatcher_tick",
                extra={
                    "worker": wid,
                    "queue_size": self.queue.qsize(),
                    "inflight_locked": self.inflight.locked(),
                },
            )

            # ğŸ”¥ ä¸ await RPC
            asyncio.create_task(
                self._execute_rpc(method, params, fut, meta, wid)
            )

            self.queue.task_done()

    async def _execute_rpc(self, method, params, fut, meta, wid):
        
        log.debug(
            "â³ rpc_wait_inflight",
            extra={
                "task_id": meta.task_id,
                "method": method,
                "queue_size": self.queue.qsize(),
            },
        )

        async with self.inflight:
            # rpc_start_ts = time.time()

            m().rpc_started.inc()
            m().rpc_inflight.inc()
            
            log.info(
                "ğŸš€ rpc_started",
                extra={
                    "task_id": meta.task_id,
                    "method": method,
                    "worker": wid,
                },
            )

            try:
                result, rpc, key_env, trace = await self.router.call_once(
                    method, params
                )
                
                m().rpc_completed_inc(rpc, key_env)
                
                if trace and trace.total_ms is not None:
                    # key çº§åˆ«çš„é—®é¢˜ ç”¨ Counter çœ‹ï¼Œå»¶è¿Ÿåˆ†å¸ƒ åªçœ‹ provider çº§
                    m().rpc_latency_observe(rpc, trace.total_ms)
                    
                if not fut.done():
                    fut.set_result(
                        (result, rpc, key_env, trace, wid, meta)
                    )

                # log.info(
                #     "rpc_call_done",
                #     extra={
                #         "task_id": meta.task_id,
                #         # "worker": wid,
                #         "rpc": rpc,
                #         "key_env": key_env,
                #         "latency_ms": round(
                #             (time.time() - rpc_start_ts) * 1000, 2
                #         ),
                #     },
                # )

            except Exception as e:
                # log.warning(
                #     "âš ï¸ rpc_call_error",
                #     extra={
                #         "task_id": meta.task_id,
                #         # "worker": wid,
                #         "error_type": type(e).__name__,
                #         "error": str(e),
                #     },
                # )
            
                if not fut.done():
                    fut.set_result(
                        RpcErrorResult(
                            error=e,
                            rpc=None,
                            key_env=None,
                            meta=meta,
                            wid=wid,
                        )
                    )
            finally:
                m().rpc_inflight.dec()
                m().rpc_finished_inc()
                
                log.info(
                    "ğŸ§¹ rpc_task_finished",
                    extra={
                        "task_id": meta.task_id,
                        "method": method,
                        "worker": wid,
                        "inflight_remaining": self.inflight._value,
                    },
                )


    async def close(self):
        if self._closed:
            return
    
        self._closed = True
    
        # ç­‰å¾…æ‰€æœ‰ submit çš„ä»»åŠ¡è¢« dispatcher æ¶ˆåŒ–
        await self.queue.join()
    
        # ç»™ dispatcher å‘é€€å‡ºä¿¡å·
        for _ in self.workers:
            await self.queue.put(_STOP)
    
        # ç­‰ dispatcher æ­£å¸¸é€€å‡º
        await asyncio.gather(*self.workers, return_exceptions=True)
