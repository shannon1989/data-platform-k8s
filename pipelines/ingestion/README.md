# Exactly-Once ingestion and store the state with compacted topic
  - pipeline containerization
  - Block-based ingestion
  - Time-based backfill
  - Kafka Exactly-Once
  - Compact topic state
  - Streaming / Batch jobs
  - Airflow scheduler supported

eth_backfill_job.py
-> show progress of block data ingestion (eg. 6%)
-> gost proxy for stablizied RPC
-> Linux server date accuracy issue.

# build docker image inside k8s docker

```bash
eval $(minikube docker-env)
```

```bash
docker build -t eth-ingestion:latest .
```

```YAML
kubectl create secret generic eth-secrets \
  -n airflow \
  --from-literal=rpc_url=https://mainnet.infura.io/v3/YOUR_API_KEY

kubectl create secret generic etherscan \
  -n airflow \
  --from-literal=api_key=YOUR_API_KEY
```


### Create topic
```YAML
apiVersion: batch/v1
kind: Job
metadata:
  name: create-eth-state-topic
  namespace: kafka
spec:
  backoffLimit: 1
  template:
    spec:
      restartPolicy: Never
      containers:
      - name: kafka-client
        image: quay.io/strimzi/kafka:0.49.1-kafka-4.1.1
        # kafka-topics.sh path is different in Strimzi images
        command:
          - sh
          - -c
          - |
            /opt/kafka/bin/kafka-topics.sh --create \
              --topic eth-ingestion-state \
              --bootstrap-server kafka-kafka-bootstrap.kafka.svc.cluster.local:9092 \
              --partitions 1 \
              --replication-factor 1 \
              --config cleanup.policy=compact || true

```

### Emoji rules

- â–¶ï¸  job start
- â¸ï¸  idle / waiting
- ğŸ“¦  batch start
- âœ…  success / commit
- âš ï¸  retryable warning
- âŒ  single operation failed
- ğŸ”¥  transaction aborted / fatal


## Dagster 

1. build image
eval $(minikube docker-env)
docker build -t eth-backfill:0.1.4 .

Clash ubuntu server install:
```bash
sudo wget https://github.com/MetaCubeX/mihomo/releases/download/Prerelease-Alpha/mihomo-linux-amd64-v2-alpha-1e1434d.gz
```

Check previous log:
kubectl logs -n airflow bsc-logs-ingestion-b548dcf69-ftxzh --previous

Search logs inside the POD:
```bash
kubectl logs -n airflow deploy/base-logs-ingestion \
  | jq 'select(.level=="WARNING")'
```

å¼€æºç»„ä»¶ï¼šstakater/reloader
kubectl apply -f https://raw.githubusercontent.com/stakater/Reloader/master/deployments/kubernetes/reloader.yaml

metadata:
  annotations:
    reloader.stakater.com/auto: "true"

ConfigMap ä¸€æ”¹ -> Pod è‡ªåŠ¨é‡å¯

spec:
  replicas: 1
  strategy:
    type: Recreate # å¼ºåˆ¶å•å®ä¾‹ + ä¸²è¡Œåˆ‡æ¢ ï¼ˆå…ˆ kill æ—§ Podï¼Œå†å»ºæ–° Podï¼‰Kafka EOS å®‰å…¨

## Data modeling

bsc_blocks (only blocks without full transactions)
bsc_transactions (only full transactions)
bsc_logs (only logs)


1ï¸âƒ£ `blocks` â€”â€” æ—¶é—´è½´ & å…¨å±€å‚ç…§ç³»
- block_number
- block_timestamp
- miner / proposer
- baseFee / gasLimitï¼ˆEIP-1559 é“¾ï¼‰
- parentHash â†’ reorg åˆ¤æ–­

ğŸ“Œ ä½œç”¨ï¼š
- æ‰€æœ‰äº‹å®è¡¨çš„æ—¶é—´ç»´åº¦
- checkpoint / exactly-once
- é“¾çº§ç»Ÿè®¡ï¼ˆTPSã€gasï¼‰

âŒ ä¸æ‰¿è½½ä¸šåŠ¡äº‹ä»¶


2ï¸âƒ£ `transactions` â€”â€” äº¤æ˜“â€œæ„å›¾å±‚â€

- from / to
- valueï¼ˆåŸç”Ÿå¸è½¬è´¦ï¼‰
- input dataï¼ˆå‡½æ•°è°ƒç”¨ï¼‰
- gas / gasPrice / nonce

ğŸ“Œ ä½œç”¨ï¼š

- EOA â†’ EOA è½¬è´¦
- è°è°ƒç”¨äº†è°ï¼ˆcall graph èµ·ç‚¹ï¼‰
- æ–¹æ³•çº§åˆ†æï¼ˆfunction selectorï¼‰

â—ï¸æ³¨æ„ï¼š
- ç»å¤§å¤šæ•°â€œä¸šåŠ¡äº‹å®â€ä¸åœ¨è¿™é‡Œ


3ï¸âƒ£ `logs` â€”â€” äº‹å®çœŸç›¸å±‚ï¼ˆæœ€é‡è¦ï¼‰

- ERC20 Transfer
- DEX Swap / Mint / Burn
- NFT Mint / Transfer
- å€Ÿè´·ã€æ¸…ç®—ã€è´¨æŠ¼ã€æ²»ç†

ğŸ“Œ è¿™æ˜¯å”¯ä¸€å¯é çš„â€œä¸šåŠ¡äº‹å®æºâ€

- åªè¦åˆçº¦ emitï¼Œä½ å°±ä¸€å®šèƒ½çœ‹åˆ°


| åœºæ™¯           | blocks | tx | logs | æ˜¯å¦è¦†ç›– |
| ------------ | ------ | -- | ---- | ---- |
| BNB è½¬è´¦       | âŒ      | âœ…  | âŒ    | âœ…    |
| ERC20 è½¬è´¦     | âŒ      | âŒ  | âœ…    | âœ…    |
| åˆçº¦è°ƒç”¨         | âŒ      | âœ…  | âš ï¸   | âœ…    |
| DEX Swap     | âŒ      | âŒ  | âœ…    | âœ…    |
| LP Mint/Burn | âŒ      | âŒ  | âœ…    | âœ…    |
| NFT è½¬ç§»       | âŒ      | âŒ  | âœ…    | âœ…    |
| Internal Tx  | âŒ      | âŒ  | âŒ    | âŒ    |
| æ²¡æœ‰ emit çš„é€»è¾‘  | âŒ      | âš ï¸ | âŒ    | âŒ    |

get_balance
- logs + tx è®¡ç®—


Reorg:

removed = true

if removed:
    delta_amount = -original_delta
ğŸ“Œ balance æ˜¯ å¯é€†çš„


Kafka
 â†’ Avro decode
 â†’ column å¤„ç†
 â†’ order / select
 â†’ Iceberg writer
 â†’ S3A / MinIO IO
 â†’ Iceberg commit

| é˜¶æ®µ                       | ç‰¹ç‚¹                  |
| ------------------------ | ------------------- |
| Kafka read               | è¿˜è¡Œ                  |
| Avro decode              | CPU å¯†é›†              |
| DataFrame transformation | ä¸­ç­‰                  |
| Iceberg write            | **é‡ IO + metadata** |
| MinIO S3A                | ç½‘ç»œ + fsync          |
| Iceberg commit           | driver + metadata   |


Kafka â†’ Spark â†’ ClickHouse â‰ˆ 1â€“2s
ğŸ‘‰ Spark micro-batch + ClickHouse batch insert = å¤©ä½œä¹‹åˆ

| éœ€æ±‚               | ç»“è®º          |
| ---------------- | ----------- |
| 100ms çº§ SLA      | âŒ Spark ä¸åˆé€‚ |
| å®æ—¶å‘Šè­¦ / CEP       | âŒ Spark ä¸åˆé€‚ |
| ç§’çº§ BI / çœ‹æ¿       | âœ… Spark å¾ˆåˆé€‚ |
| å¤§ååå†™å…¥            | âœ… Spark å¾ˆåˆé€‚ |
| å¤æ‚ SQL transform | âœ… Spark å¾ˆåˆé€‚ |

```TXT
Kafka
 â”œâ”€ Spark â†’ Iceberg      ï¼ˆäº‹å®å±‚ / å›æ”¾ï¼‰ - processTime = 60 seconds
 â””â”€ Spark â†’ ClickHouse   ï¼ˆç§’çº§ OLAPï¼‰     - processTime = 1 seconds
```

| åè¯            | è¡Œä¸šå®é™…å«ä¹‰        |
| ------------- | ------------- |
| Real-time     | <100ms        |
| Streaming     | <1s           |
| Near realtime | å‡ åç§’ ~ å‡ åˆ†é’Ÿ |
| Batch         | â‰¥ 5â€“10 åˆ†é’Ÿ     |

```TXT
Spark DataFrame
   â†“
Arrow Columnar Batchï¼ˆåˆ—å¼å†…å­˜ï¼‰
   â†“ï¼ˆé›¶æ‹·è´ / æå°‘æ‹·è´ï¼‰
pandas.DataFrame
```